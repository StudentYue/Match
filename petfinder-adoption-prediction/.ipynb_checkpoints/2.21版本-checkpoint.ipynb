{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from functools import partial\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评价函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 评价函数 Metric used for this competition \n",
    "# (Quadratic Weigthed Kappa aka Quadratic Cohen Kappa Score)\n",
    "def metric(y1,y2):\n",
    "    return cohen_kappa_score(y1, y2, weights = 'quadratic')\n",
    "\n",
    "\n",
    "# Make scorer for scikit-learn\n",
    "scorer = make_scorer(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#\n",
    "def split_score(model, x, y, n=10):\n",
    "    y_pre = np.zeros(y.shape[0])\n",
    "    kfold = StratifiedKFold(n_splits=n, random_state=1337)\n",
    "    for train_index, test_index in kfold.split(x,y):\n",
    "        model.fit(x.iloc[train_index], y.iloc[train_index])\n",
    "        y_pre[test_index] = model.predict(x.iloc[test_index])\n",
    "    \n",
    "#    score = metric(y_pre, y)\n",
    "    print(\"{}折后的Kappa加权得分为:带补充\".format(n))\n",
    "    \n",
    "    return y_pre\n",
    "\n",
    "#\n",
    "def fix_y(y, coef):\n",
    "    y_fix = np.copy(y)\n",
    "    for i, pred in enumerate(y_fix):\n",
    "        if pred < coef[0]:\n",
    "            y_fix[i] = 0\n",
    "        elif pred >= coef[0] and pred < coef[1]:\n",
    "            y_fix[i] = 1\n",
    "        elif pred >= coef[1] and pred < coef[2]:\n",
    "            y_fix[i] = 2\n",
    "        elif pred >= coef[2] and pred < coef[3]:\n",
    "            y_fix[i] = 3\n",
    "        else:\n",
    "            y_fix[i] = 4    \n",
    "    return y_fix\n",
    "\n",
    "# \n",
    "def _kappa_loss(y, y_true, coef):\n",
    "    y_fix = np.copy(y)\n",
    "    for i, pred in enumerate(y_fix):\n",
    "        if pred < coef[0]:\n",
    "            y_fix[i] = 0\n",
    "        elif pred >= coef[0] and pred < coef[1]:\n",
    "            y_fix[i] = 1\n",
    "        elif pred >= coef[1] and pred < coef[2]:\n",
    "            y_fix[i] = 2\n",
    "        elif pred >= coef[2] and pred < coef[3]:\n",
    "            y_fix[i] = 3\n",
    "        else:\n",
    "            y_fix[i] = 4\n",
    "            \n",
    "    loss = metric(y_fix, y_true)\n",
    "    return -loss\n",
    "\n",
    "# 寻找分类的最佳参数\n",
    "def search_coef(x1, x2):\n",
    "    loss_partial = partial(_kappa_loss, x1, x2)\n",
    "    initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "    coef = sp.optimize.basinhopping(loss_partial, initial_coef, niter=500, T=1,\n",
    "                                              stepsize=0.2, minimizer_kwargs={\"method\": 'nelder-mead'}, \n",
    "                                              take_step=None, accept_test=None, callback=None, \n",
    "                                              interval=100, disp=True, niter_success=20, seed=None)\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-6-08733a7f93b9>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-08733a7f93b9>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    self.coef_ = sp.optimize.basinhopping(loss_partial, initial_coef, niter=500, T=1,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "#        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "        self.coef_ = sp.optimize.basinhopping(loss_partial, initial_coef, niter=500, T=1,\n",
    "                                              stepsize=0.2, minimizer_kwargs={\"method\": 'nelder-mead'}, \n",
    "                                              take_step=None, accept_test=None, callback=None, \n",
    "                                              interval=100, disp=True, niter_success=20, seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train  = pd.read_csv('train.csv')\n",
    "df_test   = pd.read_csv('test.csv')\n",
    "\n",
    "train = df_train.copy()\n",
    "test  = df_test.copy()\n",
    "\n",
    "labels_breed = pd.read_csv('breed_labels.csv')\n",
    "labels_state = pd.read_csv('color_labels.csv')\n",
    "labels_color = pd.read_csv('state_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1518.000000\n",
       "mean        2.600791\n",
       "std         6.862242\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max       146.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df_test.groupby('RescuerID').size()\n",
    "type(a)\n",
    "a.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/root/anaconda3/nltk_data'\n    - '/root/anaconda3/share/nltk_data'\n    - '/root/anaconda3/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-44c53efef077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'like'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \"\"\"\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'file:'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/root/anaconda3/nltk_data'\n    - '/root/anaconda3/share/nltk_data'\n    - '/root/anaconda3/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.pos_tag(['i', 'like'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Nibble, is, a, 3+, month, old, ball, of, cute...\n",
       "1    [I, just, found, it, alone, yesterday, near, m...\n",
       "2    [Their, pregnant, mother, was, dumped, by, her...\n",
       "3    [Good, guard, dog, ,, very, alert, ,, active, ...\n",
       "4    [This, handsome, yet, cute, boy, is, up, for, ...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import brown.tagged_words #导入布朗语料库\n",
    "\n",
    "a = df_train['Description'].apply(lambda x:nltk.word_tokenize(x))\n",
    "\n",
    "#1 去掉标点符号和停用词\n",
    "#去掉标点符号\n",
    "english_punctuations = [',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%']\n",
    "b = a.apply(lambda x:[word for word in x if word not in english_punctuations])\n",
    "\n",
    "#去掉停用词\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "c = b.apply(lambda x:[set(x).intersection(objective)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [{energetic, responsible, playful, little, old...\n",
       "1                         [{near, alone, temporary, just}]\n",
       "2        [{long, healthy, adorable, pregnant, precautio...\n",
       "3        [{active, master, very, Good, interested, aler...\n",
       "4        [{such, looking, playful, young, cute, like, h...\n",
       "5                                                [{stray}]\n",
       "6                     [{outside, interested, still, just}]\n",
       "7                                                 [{just}]\n",
       "8                                [{active, sure, healthy}]\n",
       "9        [{long, very, gentle, soft, high, cute, like, ...\n",
       "10                                             [{serious}]\n",
       "11       [{super, active, long, routine, playful, singl...\n",
       "12                         [{active, happy, very, neuter}]\n",
       "13                    [{long, evident, cute, stray, good}]\n",
       "14                                        [{red, healthy}]\n",
       "15       [{loyal, looking, fun-loving, friendly, great,...\n",
       "16                                  [{friendly, adorable}]\n",
       "17                      [{active, even, male, like, good}]\n",
       "18       [{black, full, clean, only, safe, trying, read...\n",
       "19       [{super, back, sweet, curious, very, Female, s...\n",
       "20       [{residential, beautiful, left, only, stray, a...\n",
       "21                               [{cute, active, healthy}]\n",
       "22                                                    [{}]\n",
       "23                                      [{friendly, very}]\n",
       "24            [{wan, indoor, resident, happy, good, just}]\n",
       "25       [{short, daily, large, very, soft, thick, Calm...\n",
       "26                        [{cute, easy, playful, healthy}]\n",
       "27                                                [{Just}]\n",
       "28                       [{healthy, active, tall, skinny}]\n",
       "29       [{lean, indoor, like, old, neuter, still, huma...\n",
       "                               ...                        \n",
       "14963                         [{busy, active, interested}]\n",
       "14964    [{intelligent, lovely, sweet, playful, friendl...\n",
       "14965    [{Black, white, sweet, middle, curious, Normal...\n",
       "14966      [{active, healthy, playful, sure, stray, just}]\n",
       "14967    [{adult, certain, full, very, indoor, new, due...\n",
       "14968                     [{cute, outside, new, pregnant}]\n",
       "14969    [{back, Just, fit, Good, bad, indoor, Ideal, n...\n",
       "14970    [{proper, very, only, left, kindly, little, st...\n",
       "14971    [{white, only, fluffy, soft, down, golden, und...\n",
       "14972    [{energetic, clever, lovely, looking, little, ...\n",
       "14973                                                 [{}]\n",
       "14974                  [{healthy, very, cute, born, well}]\n",
       "14975                                        [{old, good}]\n",
       "14976                                             [{Free}]\n",
       "14977             [{close, indoor, friendly, good, human}]\n",
       "14978    [{live, spare, heavy, pretty, future, left, li...\n",
       "14979                                      [{good, human}]\n",
       "14980       [{energetic, kind, playful, very, side, good}]\n",
       "14981                                             [{free}]\n",
       "14982    [{late, own, oral, adorable, precious, very, o...\n",
       "14983    [{real, long, intelligent, very, precautionary...\n",
       "14984                                          [{healthy}]\n",
       "14985                                             [{good}]\n",
       "14986          [{commit, white, grey, medical, near, old}]\n",
       "14987                                                 [{}]\n",
       "14988    [{healthy, lovely, playful, very, pregnant, ch...\n",
       "14989                  [{white, male, cream, old, female}]\n",
       "14990                                   [{friendly, good}]\n",
       "14991                                       [{very, just}]\n",
       "14992                               [{quiet, under, just}]\n",
       "Name: Description, Length: 14993, dtype: object"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alone', 'just', 'near', 'temporary'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(b[1]).intersection(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_corpus = (nltk.corpus.brown.tagged_words())\n",
    "objective = [word for (word, tap) in brown_corpus if tap == 'JJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64028"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 844)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nibble': 498,\n",
       " 'old': 512,\n",
       " 'energetic': 222,\n",
       " 'playful': 546,\n",
       " 'couple': 158,\n",
       " 'neutered': 493,\n",
       " 'clinic': 134,\n",
       " 'little': 417,\n",
       " 'kitty': 387,\n",
       " 'responsible': 609,\n",
       " 'temporary': 731,\n",
       " 'pregnant': 562,\n",
       " 'irresponsible': 374,\n",
       " 'healthy': 323,\n",
       " 'adorable': 27,\n",
       " 'vaccinated': 797,\n",
       " 'ready': 592,\n",
       " 'long': 421,\n",
       " 'acceptable': 10,\n",
       " 'tie': 741,\n",
       " 'precautionary': 559,\n",
       " 'interested': 370,\n",
       " 'adopt': 23,\n",
       " 'good': 299,\n",
       " 'active': 13,\n",
       " 'cute': 166,\n",
       " 'young': 836,\n",
       " 'stray': 703,\n",
       " 'hometown': 334,\n",
       " 'outside': 518,\n",
       " 'sure': 716,\n",
       " 'manja': 444,\n",
       " 'gentle': 293,\n",
       " 'high': 328,\n",
       " 'soft': 678,\n",
       " 'super': 715,\n",
       " 'quiet': 585,\n",
       " 'cuddle': 163,\n",
       " 'toys': 752,\n",
       " 'busy': 108,\n",
       " 'half': 315,\n",
       " 'normal': 504,\n",
       " 'single': 662,\n",
       " 'second': 634,\n",
       " 'info': 360,\n",
       " 'puppy': 580,\n",
       " 'happy': 319,\n",
       " 'vaccinate': 796,\n",
       " 'come': 142,\n",
       " 'persian': 535,\n",
       " 'red': 596,\n",
       " 'friendly': 280,\n",
       " 'neighbour': 489,\n",
       " 'fun': 282,\n",
       " 'loving': 432,\n",
       " 'great': 305,\n",
       " 'loyal': 434,\n",
       " 'english': 223,\n",
       " 'male': 442,\n",
       " 'safe': 626,\n",
       " 'cats': 117,\n",
       " 'clean': 131,\n",
       " 'black': 88,\n",
       " 'able': 7,\n",
       " 'contact': 153,\n",
       " 'sms': 674,\n",
       " 'sweet': 719,\n",
       " 'big': 84,\n",
       " 'curious': 164,\n",
       " 'adventurous': 29,\n",
       " 'lovable': 427,\n",
       " 'residential': 608,\n",
       " 'afraid': 32,\n",
       " 'human': 340,\n",
       " 'fed': 244,\n",
       " 'gorgeous': 300,\n",
       " 'beautiful': 80,\n",
       " 'bed': 81,\n",
       " 'borne': 93,\n",
       " 'adopter': 25,\n",
       " 'indoor': 357,\n",
       " 'large': 395,\n",
       " 'daily': 168,\n",
       " 'short': 650,\n",
       " 'fur': 286,\n",
       " 'easy': 214,\n",
       " 'kitten': 385,\n",
       " 'dewormed': 183,\n",
       " 'follow': 268,\n",
       " 'vaccination': 798,\n",
       " 'brown': 103,\n",
       " 'white': 819,\n",
       " 'new': 495,\n",
       " 'mummy': 473,\n",
       " 'solid': 679,\n",
       " 'willing': 822,\n",
       " 'welcome': 816,\n",
       " 'open': 513,\n",
       " 'fat': 240,\n",
       " 'cat': 116,\n",
       " 'di': 184,\n",
       " 'untuk': 783,\n",
       " 'tinggal': 744,\n",
       " 'unnecessarily': 780,\n",
       " 'wish': 823,\n",
       " 'guard': 311,\n",
       " 'birth': 85,\n",
       " 'malaysian': 441,\n",
       " 'shy': 652,\n",
       " 'potential': 556,\n",
       " 'wait': 807,\n",
       " 'unable': 771,\n",
       " 'siamese': 653,\n",
       " 'blue': 90,\n",
       " 'eyed': 232,\n",
       " 'leg': 402,\n",
       " 'rescue': 604,\n",
       " 'pair': 522,\n",
       " 'spay': 683,\n",
       " 'special': 686,\n",
       " 'heavy': 325,\n",
       " 'mannered': 445,\n",
       " 'ill': 347,\n",
       " 'treated': 757,\n",
       " 'previous': 567,\n",
       " 'medical': 449,\n",
       " 'home': 331,\n",
       " 'haired': 314,\n",
       " 'suitable': 713,\n",
       " 'baby': 73,\n",
       " 'simple': 661,\n",
       " 'ur': 789,\n",
       " 'female': 251,\n",
       " 'sleep': 668,\n",
       " 'talkative': 726,\n",
       " 'different': 189,\n",
       " 'total': 749,\n",
       " 'colour': 140,\n",
       " 'obedient': 507,\n",
       " 'affectionate': 30,\n",
       " 'small': 671,\n",
       " 'left': 401,\n",
       " 'mum': 472,\n",
       " 'extra': 231,\n",
       " 'meal': 447,\n",
       " 'handle': 316,\n",
       " 'cage': 109,\n",
       " 'homeless': 333,\n",
       " 'free': 275,\n",
       " 'fleas': 265,\n",
       " 'sad': 625,\n",
       " 'behaved': 83,\n",
       " 'perfect': 533,\n",
       " 'month': 469,\n",
       " 'industrial': 359,\n",
       " 'minor': 461,\n",
       " 'american': 46,\n",
       " 'available': 69,\n",
       " 'type': 768,\n",
       " 'fluffy': 267,\n",
       " 'pls': 550,\n",
       " 'park': 524,\n",
       " 'rainy': 587,\n",
       " 'survive': 718,\n",
       " 'cold': 136,\n",
       " 'yearly': 832,\n",
       " 'initial': 363,\n",
       " 'whatsapp': 818,\n",
       " 'lady': 389,\n",
       " 'ppl': 558,\n",
       " 'trained': 755,\n",
       " 'roadside': 615,\n",
       " 'mixed': 465,\n",
       " 'fast': 239,\n",
       " 'know': 388,\n",
       " 'train': 753,\n",
       " 'dog': 197,\n",
       " 'dogs': 200,\n",
       " 'smart': 672,\n",
       " 'poor': 553,\n",
       " 'skin': 666,\n",
       " 'bath': 78,\n",
       " 'tick': 739,\n",
       " 'fish': 260,\n",
       " 'adjustable': 22,\n",
       " 'potty': 557,\n",
       " 'app': 56,\n",
       " 'future': 289,\n",
       " 'provide': 576,\n",
       " 'sufficient': 712,\n",
       " 'allow': 42,\n",
       " 'comfortable': 144,\n",
       " 'basic': 77,\n",
       " 'complete': 148,\n",
       " 'agree': 34,\n",
       " 'factory': 233,\n",
       " 'non': 503,\n",
       " 'hungry': 341,\n",
       " 'mother': 471,\n",
       " 'friend': 279,\n",
       " 'foster': 271,\n",
       " 'dengan': 179,\n",
       " 'live': 418,\n",
       " 'neighbourhood': 490,\n",
       " 'grey': 307,\n",
       " 'protective': 575,\n",
       " 'alert': 38,\n",
       " 'hyper': 343,\n",
       " 'nice': 499,\n",
       " 'roam': 616,\n",
       " 'dry': 208,\n",
       " 'animal': 50,\n",
       " 'everyday': 225,\n",
       " 'frequent': 276,\n",
       " 'excited': 228,\n",
       " 'bad': 74,\n",
       " 'tummy': 766,\n",
       " 'permanent': 534,\n",
       " 'inside': 368,\n",
       " 'successful': 711,\n",
       " 'independent': 354,\n",
       " 'occasional': 509,\n",
       " 'want': 810,\n",
       " 'illness': 348,\n",
       " 'angry': 49,\n",
       " 'terrible': 733,\n",
       " 'strong': 707,\n",
       " 'precious': 560,\n",
       " 'golden': 298,\n",
       " 'clear': 132,\n",
       " 'personal': 536,\n",
       " 'cutie': 167,\n",
       " 'coz': 159,\n",
       " 'makan': 439,\n",
       " 'ni': 497,\n",
       " 'boleh': 91,\n",
       " 'amazing': 45,\n",
       " 'funny': 285,\n",
       " 'hot': 337,\n",
       " 'stay': 694,\n",
       " 'email': 220,\n",
       " 'lovely': 430,\n",
       " 'sit': 664,\n",
       " 'text': 735,\n",
       " 'pet': 538,\n",
       " 'update': 785,\n",
       " 'pure': 582,\n",
       " 'german': 295,\n",
       " 'bark': 76,\n",
       " 'poo': 551,\n",
       " 'difficult': 190,\n",
       " 'spend': 687,\n",
       " 'nearby': 483,\n",
       " 'ini': 362,\n",
       " 'caught': 118,\n",
       " 'yellow': 833,\n",
       " 'lick': 407,\n",
       " 'expensive': 229,\n",
       " 'huge': 339,\n",
       " 'lazy': 397,\n",
       " 'born': 92,\n",
       " 'hyperactive': 344,\n",
       " 'preferable': 561,\n",
       " 'profile': 570,\n",
       " 'fantastic': 238,\n",
       " 'entire': 224,\n",
       " 'possible': 555,\n",
       " 'steady': 695,\n",
       " 'kibble': 383,\n",
       " 'calm': 111,\n",
       " 'excellent': 227,\n",
       " 'aktif': 37,\n",
       " 'pedigree': 531,\n",
       " 'vet': 800,\n",
       " 'sent': 642,\n",
       " 'rehome': 599,\n",
       " 'pup': 579,\n",
       " 'inquisitive': 366,\n",
       " 'greyish': 308,\n",
       " 'dark': 172,\n",
       " 'underneath': 775,\n",
       " 'intelligent': 369,\n",
       " 'legs': 403,\n",
       " 'wide': 820,\n",
       " 'adoption': 26,\n",
       " 'litter': 415,\n",
       " 'spayed': 684,\n",
       " 'compulsory': 149,\n",
       " 'brief': 98,\n",
       " 'cautious': 119,\n",
       " 'loud': 426,\n",
       " 'low': 433,\n",
       " 'reasonable': 594,\n",
       " 'dangerous': 171,\n",
       " 'let': 405,\n",
       " 'spare': 682,\n",
       " 'ticked': 740,\n",
       " 'warm': 811,\n",
       " 'original': 516,\n",
       " 'behalf': 82,\n",
       " 'litterbox': 416,\n",
       " 'natured': 480,\n",
       " 'nervous': 491,\n",
       " 'close': 135,\n",
       " 'adult': 28,\n",
       " 'urgent': 790,\n",
       " 'deep': 176,\n",
       " 'year': 831,\n",
       " 'late': 396,\n",
       " 'pick': 540,\n",
       " 'aggressive': 33,\n",
       " 'broken': 101,\n",
       " 'severe': 645,\n",
       " 'abandoned': 6,\n",
       " 'pampered': 523,\n",
       " 'leash': 399,\n",
       " 'timid': 743,\n",
       " 'past': 526,\n",
       " 'natural': 479,\n",
       " 'cheerful': 126,\n",
       " 'hazel': 322,\n",
       " 'bottle': 94,\n",
       " 'feeding': 247,\n",
       " 'plenty': 549,\n",
       " 'lap': 394,\n",
       " 'wormed': 827,\n",
       " 'flea': 263,\n",
       " 'box': 95,\n",
       " 'right': 613,\n",
       " 'premium': 563,\n",
       " 'hair': 313,\n",
       " 'brownish': 104,\n",
       " 'stick': 697,\n",
       " 'scared': 632,\n",
       " 'abused': 8,\n",
       " 'thrown': 738,\n",
       " 'adequate': 19,\n",
       " 'green': 306,\n",
       " 'tiny': 745,\n",
       " 'regular': 598,\n",
       " 'kept': 381,\n",
       " 'cheap': 123,\n",
       " 'check': 124,\n",
       " 'unnecessary': 781,\n",
       " 'noise': 501,\n",
       " 'clever': 133,\n",
       " 'handsome': 317,\n",
       " 'boy': 96,\n",
       " 'mama': 443,\n",
       " 'mobile': 466,\n",
       " 'tough': 751,\n",
       " 'destructive': 181,\n",
       " 'social': 677,\n",
       " 'comel': 143,\n",
       " 'slight': 669,\n",
       " 'dominant': 202,\n",
       " 'similar': 660,\n",
       " 'real': 593,\n",
       " 'submissive': 709,\n",
       " 'shelter': 647,\n",
       " 'fellow': 250,\n",
       " 'rm': 614,\n",
       " 'quick': 584,\n",
       " 'eat': 215,\n",
       " 'sensitive': 641,\n",
       " 'use': 791,\n",
       " 'forever': 270,\n",
       " 'middle': 456,\n",
       " 'local': 420,\n",
       " 'nap': 478,\n",
       " 'breed': 97,\n",
       " 'distinctive': 194,\n",
       " 'lucky': 435,\n",
       " 'angel': 48,\n",
       " 'appointment': 58,\n",
       " 'need': 485,\n",
       " 'tabby': 722,\n",
       " 'ok': 510,\n",
       " 'separate': 643,\n",
       " 'flat': 262,\n",
       " 'lil': 412,\n",
       " 'husky': 342,\n",
       " 'colored': 139,\n",
       " 'purr': 583,\n",
       " 'tried': 760,\n",
       " 'bite': 87,\n",
       " 'fresh': 277,\n",
       " 'wet': 817,\n",
       " 'upload': 787,\n",
       " 'grown': 310,\n",
       " 'convenient': 155,\n",
       " 'japanese': 376,\n",
       " 'girl': 296,\n",
       " 'proof': 572,\n",
       " 'typical': 769,\n",
       " 'cherish': 127,\n",
       " 'intro': 373,\n",
       " 'pertinent': 537,\n",
       " 'hard': 320,\n",
       " 'hearted': 324,\n",
       " 'wonderful': 824,\n",
       " 'umur': 770,\n",
       " 'tuan': 764,\n",
       " 'akan': 36,\n",
       " 'fight': 255,\n",
       " 'pretty': 565,\n",
       " 'dia': 185,\n",
       " 'mail': 436,\n",
       " 'spoken': 689,\n",
       " 'proper': 573,\n",
       " 'silky': 659,\n",
       " 'finish': 259,\n",
       " 'going': 297,\n",
       " 'weak': 814,\n",
       " 'unique': 778,\n",
       " 'sick': 654,\n",
       " 'early': 213,\n",
       " 'distinct': 193,\n",
       " 'rubbish': 621,\n",
       " 'chinese': 129,\n",
       " 'poodle': 552,\n",
       " 'like': 409,\n",
       " 'additional': 18,\n",
       " 'paws': 530,\n",
       " 'pleasant': 548,\n",
       " 'apartment': 55,\n",
       " '他是被丢在工业区的宝宝': 837,\n",
       " '这里两条街大概只狗狗': 843,\n",
       " '因为狗狗太多的关系已经惹得店家的厌恶': 838,\n",
       " '被报了两次mpsj': 841,\n",
       " '还被追打': 842,\n",
       " '狗狗是无辜的': 840,\n",
       " '没人想当一只被人厌恶的狗': 839,\n",
       " 'attached': 66,\n",
       " 'current': 165,\n",
       " 'accident': 11,\n",
       " 'domestic': 201,\n",
       " 'asap': 63,\n",
       " 'present': 564,\n",
       " 'agreeable': 35,\n",
       " 'used': 792,\n",
       " 'nutritious': 506,\n",
       " 'necessary': 484,\n",
       " 'rid': 612,\n",
       " 'strange': 702,\n",
       " 'temperament': 730,\n",
       " 'light': 408,\n",
       " 'fine': 258,\n",
       " 'tail': 724,\n",
       " 'ball': 75,\n",
       " 'harsh': 321,\n",
       " 'lose': 423,\n",
       " 'uncle': 772,\n",
       " 'utk': 794,\n",
       " 'seek': 635,\n",
       " 'fussy': 288,\n",
       " 'faithful': 235,\n",
       " 'fit': 261,\n",
       " 'loveable': 429,\n",
       " 'familiar': 236,\n",
       " 'crazy': 160,\n",
       " 'docile': 195,\n",
       " 'hole': 330,\n",
       " 'patient': 528,\n",
       " 'medium': 451,\n",
       " 'dead': 173,\n",
       " 'prior': 568,\n",
       " 'weight': 815,\n",
       " 'keen': 379,\n",
       " 'monthly': 470,\n",
       " 'sociable': 676,\n",
       " 'famous': 237,\n",
       " 'sharp': 646,\n",
       " 'confident': 151,\n",
       " 'careful': 115,\n",
       " 'brought': 102,\n",
       " 'common': 147,\n",
       " 'financial': 257,\n",
       " 'overall': 519,\n",
       " 'straight': 701,\n",
       " 'orange': 515,\n",
       " 'skinny': 667,\n",
       " 'feed': 246,\n",
       " 'hope': 335,\n",
       " 'sister': 663,\n",
       " 'visit': 804,\n",
       " 'kind': 384,\n",
       " 'neutering': 494,\n",
       " 'understand': 776,\n",
       " 'walks': 808,\n",
       " 'favourite': 242,\n",
       " 'stable': 691,\n",
       " 'routine': 620,\n",
       " 'territorial': 734,\n",
       " 'capable': 112,\n",
       " 'listen': 414,\n",
       " 'avoid': 71,\n",
       " 'incapable': 353,\n",
       " 'injured': 364,\n",
       " 'rest': 611,\n",
       " 'nose': 505,\n",
       " 'snuggle': 675,\n",
       " 'chicken': 128,\n",
       " 'rare': 589,\n",
       " 'cared': 114,\n",
       " 'strays': 704,\n",
       " 'limited': 413,\n",
       " 'unfortunate': 777,\n",
       " 'voiceless': 806,\n",
       " 'immediate': 350,\n",
       " 'noisy': 502,\n",
       " 'favorite': 241,\n",
       " 'ada': 15,\n",
       " 'flead': 264,\n",
       " 'sorry': 680,\n",
       " 'innocent': 365,\n",
       " 'constant': 152,\n",
       " 'fosterer': 273,\n",
       " 'kawasan': 378,\n",
       " 'appetite': 57,\n",
       " 'likely': 410,\n",
       " 'ear': 212,\n",
       " 'mischievous': 462,\n",
       " 'pee': 532,\n",
       " 'doggie': 198,\n",
       " 'mild': 457,\n",
       " 'contribute': 154,\n",
       " 'spot': 690,\n",
       " 'anti': 52,\n",
       " 'abandon': 5,\n",
       " 'wan': 809,\n",
       " 'sangat': 627,\n",
       " 'negotiable': 487,\n",
       " 'drop': 207,\n",
       " 'protect': 574,\n",
       " 'till': 742,\n",
       " 'genuine': 294,\n",
       " 'drain': 206,\n",
       " 'touch': 750,\n",
       " 'municipal': 474,\n",
       " 'rescued': 605,\n",
       " 'indoors': 358,\n",
       " 'fenced': 252,\n",
       " '20': 1,\n",
       " 'fungus': 284,\n",
       " 'condo': 150,\n",
       " 'appreciated': 60,\n",
       " 'unwanted': 784,\n",
       " 'grateful': 302,\n",
       " 'dirty': 192,\n",
       " 'visible': 803,\n",
       " 'sticky': 698,\n",
       " 'private': 569,\n",
       " 'fungal': 283,\n",
       " 'remarkable': 602,\n",
       " 'aware': 72,\n",
       " 'doggy': 199,\n",
       " 'bear': 79,\n",
       " 'exact': 226,\n",
       " 'die': 187,\n",
       " 'relevant': 600,\n",
       " 'copy': 157,\n",
       " 'stiffen': 699,\n",
       " 'undergo': 774,\n",
       " 'signboard': 657,\n",
       " 'melbourne': 453,\n",
       " 'gravel': 303,\n",
       " 'roofed': 617,\n",
       " 'important': 351,\n",
       " 'main': 437,\n",
       " 'tak': 725,\n",
       " 'sebab': 633,\n",
       " 'jealous': 377,\n",
       " 'slow': 670,\n",
       " 'street': 705,\n",
       " 'unknown': 779,\n",
       " 'adapt': 16,\n",
       " 'shiny': 648,\n",
       " 'cal': 110,\n",
       " 'dumped': 210,\n",
       " 'miss': 463,\n",
       " 'adjust': 21,\n",
       " 'cool': 156,\n",
       " 'fostered': 272,\n",
       " 'unconditional': 773,\n",
       " 'impossible': 352,\n",
       " 'puchong': 578,\n",
       " 'hit': 329,\n",
       " 'yg': 835,\n",
       " 'elderly': 218,\n",
       " 'okay': 511,\n",
       " 'diet': 188,\n",
       " 'outdoor': 517,\n",
       " 'sweetheart': 720,\n",
       " 'quite': 586,\n",
       " 'negative': 486,\n",
       " 'senior': 640,\n",
       " 'medicine': 450,\n",
       " 'alot': 44,\n",
       " 'lot': 424,\n",
       " 'im': 349,\n",
       " 'naughty': 481,\n",
       " 'play': 545,\n",
       " 'hide': 327,\n",
       " 'appreciate': 59,\n",
       " 'yellowish': 834,\n",
       " 'plastic': 544,\n",
       " 'allergic': 40,\n",
       " 'promise': 571,\n",
       " 'nak': 475,\n",
       " 'self': 637,\n",
       " '30pm': 2,\n",
       " 'opposite': 514,\n",
       " 'requirement': 603,\n",
       " 'bundle': 106,\n",
       " 'gray': 304,\n",
       " 'lover': 431,\n",
       " 'veterinary': 801,\n",
       " 'leave': 400,\n",
       " 'fr': 274,\n",
       " 'responsive': 610,\n",
       " 'commitment': 146,\n",
       " 'vocal': 805,\n",
       " 'afford': 31,\n",
       " 'fair': 234,\n",
       " 'dan': 170,\n",
       " 'nk': 500,\n",
       " 'actual': 14,\n",
       " 'collect': 138,\n",
       " 'flu': 266,\n",
       " 'gal': 290,\n",
       " 'direct': 191,\n",
       " 'bright': 99,\n",
       " 'toilet': 747,\n",
       " 'love': 428,\n",
       " 'lots': 425,\n",
       " 'usual': 793,\n",
       " 'lane': 393,\n",
       " 'wary': 812,\n",
       " 'bring': 100,\n",
       " 'living': 419,\n",
       " 'accept': 9,\n",
       " 'speak': 685,\n",
       " 'rubs': 622,\n",
       " 'ideal': 346,\n",
       " 'care': 113,\n",
       " 'doesnt': 196,\n",
       " 'ekor': 217,\n",
       " 'send': 639,\n",
       " 'stop': 700,\n",
       " 'learn': 398,\n",
       " 'yappy': 830,\n",
       " 'anak': 47,\n",
       " 'got': 301,\n",
       " 'landed': 392,\n",
       " 'rough': 618,\n",
       " 'guardian': 312,\n",
       " 'tree': 758,\n",
       " 'cream': 161,\n",
       " 'foreign': 269,\n",
       " 'taman': 728,\n",
       " 'picky': 541,\n",
       " 'certain': 120,\n",
       " 'mid': 455,\n",
       " 'resident': 607,\n",
       " 'final': 256,\n",
       " 'raw': 590,\n",
       " 'fulfill': 281,\n",
       " 'collar': 137,\n",
       " 'fearful': 243,\n",
       " 'saya': 631,\n",
       " 'tu': 763,\n",
       " 'video': 802,\n",
       " 'inseparable': 367,\n",
       " 'owner': 521,\n",
       " 'succesful': 710,\n",
       " 'true': 761,\n",
       " 'dose': 205,\n",
       " 'individual': 356,\n",
       " 'sized': 665,\n",
       " 'kesian': 382,\n",
       " 'run': 623,\n",
       " 'pups': 581,\n",
       " 'mix': 464,\n",
       " 'twice': 767,\n",
       " 'grow': 309,\n",
       " 'think': 737,\n",
       " 'house': 338,\n",
       " 'tame': 729,\n",
       " 'souls': 681,\n",
       " 'tray': 756,\n",
       " 'experienced': 230,\n",
       " 'fee': 245,\n",
       " 'spitz': 688,\n",
       " 'eager': 211,\n",
       " 'vacant': 795,\n",
       " 'neighborhood': 488,\n",
       " 'worried': 828,\n",
       " 'silent': 658,\n",
       " 'door': 204,\n",
       " 'meow': 454,\n",
       " 'read': 591,\n",
       " 'smile': 673,\n",
       " 'fierce': 254,\n",
       " 'semi': 638,\n",
       " 'tue': 765,\n",
       " 'fri': 278,\n",
       " '9am': 4,\n",
       " 'sat': 628,\n",
       " 'sun': 714,\n",
       " '10am': 0,\n",
       " 'homed': 332,\n",
       " 'public': 577,\n",
       " 'playfull': 547,\n",
       " 'ran': 588,\n",
       " 'pitiful': 542,\n",
       " 'accompany': 12,\n",
       " 'near': 482,\n",
       " 'place': 543,\n",
       " 'license': 406,\n",
       " 'worm': 826,\n",
       " 'feisty': 248,\n",
       " 'neuter': 492,\n",
       " 'lain': 391,\n",
       " 'ask': 64,\n",
       " 'elegant': 219,\n",
       " 'athletic': 65,\n",
       " 'blind': 89,\n",
       " 'vaccine': 799,\n",
       " 'pat': 527,\n",
       " 'kepong': 380,\n",
       " 'obvious': 508,\n",
       " 'bunch': 105,\n",
       " 'horrible': 336,\n",
       " 'separated': 644,\n",
       " 'meet': 452,\n",
       " 'overseas': 520,\n",
       " 'wild': 821,\n",
       " 'tri': 759,\n",
       " 'coloured': 141,\n",
       " 'deworm': 182,\n",
       " 'wassap': 813,\n",
       " 'shop': 649,\n",
       " 'selamatkan': 636,\n",
       " 'strict': 706,\n",
       " 'marble': 446,\n",
       " 'adaptable': 17,\n",
       " 'ed': 216,\n",
       " 'table': 723,\n",
       " 'dump': 209,\n",
       " 'unspayed': 782,\n",
       " 'approachable': 61,\n",
       " 'annual': 51,\n",
       " 'wrong': 829,\n",
       " 'infront': 361,\n",
       " 'nanti': 477,\n",
       " 'dont': 203,\n",
       " 'decided': 175,\n",
       " 'sight': 655,\n",
       " 'round': 619,\n",
       " 'steal': 696,\n",
       " 'particular': 525,\n",
       " 'prevent': 566,\n",
       " 'stuck': 708,\n",
       " 'appropriate': 62,\n",
       " 'adopted': 24,\n",
       " 'trainable': 754,\n",
       " 'minimum': 460,\n",
       " 'chase': 122,\n",
       " 'attentive': 67,\n",
       " 'choose': 130,\n",
       " 'saw': 630,\n",
       " 'tall': 727,\n",
       " 'bushy': 107,\n",
       " 'ibu': 345,\n",
       " 'mom': 467,\n",
       " 'refundable': 597,\n",
       " 'updates': 786,\n",
       " 'dalmatian': 169,\n",
       " 'russian': 624,\n",
       " 'make': 440,\n",
       " 'feline': 249,\n",
       " 'dear': 174,\n",
       " 'start': 692,\n",
       " 'garden': 291,\n",
       " 'antibiotic': 53,\n",
       " 'general': 292,\n",
       " 'looking': 422,\n",
       " 'newborn': 496,\n",
       " 'term': 732,\n",
       " 'tired': 746,\n",
       " 'mommy': 468,\n",
       " 'end': 221,\n",
       " 'likes': 411,\n",
       " 'surgical': 717,\n",
       " 'physical': 539,\n",
       " 'alley': 41,\n",
       " 'recent': 595,\n",
       " 'lagi': 390,\n",
       " 'tolong': 748,\n",
       " 'milk': 458,\n",
       " 'didnt': 186,\n",
       " 'alive': 39,\n",
       " 'rescuer': 606,\n",
       " 'shot': 651,\n",
       " 'desperate': 180,\n",
       " 'wont': 825,\n",
       " 'thank': 736,\n",
       " 'positive': 554,\n",
       " 'deflead': 178,\n",
       " 'sign': 656,\n",
       " 'average': 70,\n",
       " 'furry': 287,\n",
       " 'kittens': 386,\n",
       " 'indian': 355,\n",
       " 'feral': 253,\n",
       " 'bit': 86,\n",
       " 'anytime': 54,\n",
       " 'attractive': 68,\n",
       " 'cheeky': 125,\n",
       " 'interesting': 371,\n",
       " 'major': 438,\n",
       " 'happen': 318,\n",
       " 'length': 404,\n",
       " 'starter': 693,\n",
       " 'characteristic': 121,\n",
       " 'creamy': 162,\n",
       " 'ish': 375,\n",
       " 'help': 326,\n",
       " 'trust': 762,\n",
       " 'intestinal': 372,\n",
       " 'save': 629,\n",
       " 'paw': 529,\n",
       " 'adik': 20,\n",
       " 'nakal': 476,\n",
       " '6pm': 3,\n",
       " 'minimal': 459,\n",
       " 'sy': 721,\n",
       " 'deflea': 177,\n",
       " 'commercial': 145,\n",
       " 'reluctant': 601,\n",
       " 'ups': 788,\n",
       " 'mean': 448,\n",
       " 'allowable': 43}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "f = e.fillna('Missing')\n",
    "countvec = CountVectorizer( lowercase  = True, \n",
    "                            stop_words = 'english',\n",
    "                            min_df     = 10\n",
    "                            )\n",
    "a = countvec.fit_transform(f)\n",
    "\n",
    "print(a.shape)\n",
    "countvec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5595.000000\n",
       "mean        2.679714\n",
       "std        10.384820\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max       459.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df_train.groupby('RescuerID').size()\n",
    "type(a)\n",
    "a.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 删除异常值\n",
    "cul_drop = ['375905770', 'da8d4a273', '27e74e45c', '7b5bee232', '0327b8e94']\n",
    "df_train = df_train[~df_train['PetID'].isin(cul_drop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取 sentiment 的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  36 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 6704 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=8)]: Done 14993 out of 14993 | elapsed:   15.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 384 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 3948 out of 3948 | elapsed:    3.9s finished\n"
     ]
    }
   ],
   "source": [
    "def extract_sentiment_feature(i, x):    \n",
    "    feature_sentiment = pd.DataFrame(columns=['PetID', 'token', 'sentence_magnitude', 'sentence_score','document_magnitude', 'document_score'])\n",
    "\n",
    "    if x == 'train':\n",
    "        set_file = 'train'\n",
    "    else:\n",
    "        set_file = 'test'\n",
    "    \n",
    "        \n",
    "    file_name = '{}_sentiment/{}.json'.format(set_file,i)\n",
    "    try:\n",
    "        f = open(file_name, 'r')\n",
    "        sentiment_file = json.load(f)\n",
    "            \n",
    "        token = [x['name'] for x in sentiment_file['entities']]\n",
    "        token = ' '.join(token)\n",
    "            \n",
    "        sentences_sentiment = [x['sentiment'] for x in sentiment_file['sentences']]\n",
    "        sentences_sentiment = pd.DataFrame.from_dict(\n",
    "            sentences_sentiment, orient='columns').sum()\n",
    "        sentenceSentiment_magnitude = sentences_sentiment['magnitude']\n",
    "        sentenceSentiment_score     = sentences_sentiment['score']\n",
    "            \n",
    "        docementSentiment_magnitude = sentiment_file['documentSentiment']['magnitude']\n",
    "        documentSentiment_score     = sentiment_file['documentSentiment']['score']\n",
    "            \n",
    "        new = pd.DataFrame(\n",
    "                {'PetID'               :[i], \n",
    "                 'token'               : [token],\n",
    "                 'sentence_magnitude'  : [sentenceSentiment_magnitude],\n",
    "                 'sentence_score'      : [sentenceSentiment_score],\n",
    "                 'document_magnitude'  : [docementSentiment_magnitude], \n",
    "                 'document_score'      : [documentSentiment_score]})  \n",
    "        feature_sentiment = feature_sentiment.append(new)\n",
    "    except:\n",
    "        print('{}没找到'.format(file_name))\n",
    "    \n",
    "    for each in feature_sentiment.columns:\n",
    "        if each not in ['PetID','token']:\n",
    "            feature_sentiment[each] = feature_sentiment[each].astype(float)\n",
    "\n",
    "    return feature_sentiment\n",
    "\n",
    "#%%\n",
    "train_feature_sentiment = Parallel(n_jobs=8, verbose=1)(\n",
    "        delayed(extract_sentiment_feature)(i, 'train') for i in train.PetID)\n",
    "train_feature_sentiment = [x for x in train_feature_sentiment]\n",
    "train_feature_sentiment = pd.concat(train_feature_sentiment, ignore_index=True, sort=False)\n",
    "\n",
    "test_feature_sentiment = Parallel(n_jobs=8, verbose=1)(\n",
    "        delayed(extract_sentiment_feature)(i, 'test') for i in test.PetID)\n",
    "test_feature_sentiment = [x for x in test_feature_sentiment]\n",
    "test_feature_sentiment = pd.concat(test_feature_sentiment, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_sentiment.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 提取 metadata 的特征\n",
    "#file_name = 'train_metadata/000a290e4-1.json'\n",
    "#f = open(file_name, 'r')\n",
    "#metadatafile = json.load(f)\n",
    "def extract_metadata_feature(i, x):\n",
    "    feature_metadata = pd.DataFrame()\n",
    "    if x == 'train':\n",
    "        set_file = 'train'\n",
    "    else:\n",
    "        set_file = 'test'\n",
    "        \n",
    "        \n",
    "    metadata_filenames = sorted(glob.glob('{}_metadata/{}*.json'.format(set_file, i)))\n",
    "    if len(metadata_filenames) > 0:\n",
    "        feature_metadata_sub = pd.DataFrame(columns=['PetID', 'annots_score', 'color_score', 'color_pixelfrac', 'crop_conf','crop_importance', 'annots_top_desc'])\n",
    "        for ff in metadata_filenames:\n",
    "            f = open(ff, 'rb')\n",
    "            file = json.load(f)\n",
    "            #label\n",
    "            if 'labelAnnotations' in file:\n",
    "                file_annots = file['labelAnnotations'][:int(len(file['labelAnnotations']) * 0.3)]\n",
    "                file_top_score = np.asarray([x['score'] for x in file_annots]).mean()\n",
    "                file_top_desc = [x['description'] for x in file_annots]            \n",
    "            else:\n",
    "                file_top_score = np.nan\n",
    "                file_top_desc = ['']\n",
    "            #colors\n",
    "            file_colors = file['imagePropertiesAnnotation']['dominantColors']['colors']            \n",
    "            file_color_score = np.asarray([x['score'] for x in file_colors]).mean()\n",
    "            file_color_pixelfrac = np.asarray([x['pixelFraction'] for x in file_colors]).mean()            \n",
    "            #crops\n",
    "            file_crops = file['cropHintsAnnotation']['cropHints']                \n",
    "            file_crop_conf = np.asarray([x['confidence'] for x in file_crops]).mean()\n",
    "            if 'importanceFraction' in file_crops[0].keys():\n",
    "                file_crop_importance = np.asarray([x['importanceFraction'] for x in file_crops]).mean()\n",
    "            else:\n",
    "                file_crop_importance = np.nan\n",
    "    \n",
    "                \n",
    "            new = pd.DataFrame(\n",
    "                    {\n",
    "                            'PetID'          : [i],\n",
    "                            'annots_score'   : [file_top_score],\n",
    "                            'color_score'     : [file_color_score],\n",
    "                            'color_pixelfrac' : [file_color_pixelfrac],\n",
    "                            'crop_conf'       : [file_crop_conf],\n",
    "                            'crop_importance' : [file_crop_importance],\n",
    "                            'annots_top_desc' : [' '.join(file_top_desc)]})\n",
    "            feature_metadata_sub = feature_metadata_sub.append(new)\n",
    "                \n",
    "        metadata_desc = feature_metadata_sub.groupby(['PetID'])['annots_top_desc'].unique()\n",
    "        metadata_desc = metadata_desc.reset_index()\n",
    "        metadata_desc['annots_top_desc'] = metadata_desc['annots_top_desc'].apply(lambda x:' '.join(x))\n",
    "        feature_metadata_sub.drop(['annots_top_desc'], axis=1, inplace=True)\n",
    "\n",
    "        for each in feature_metadata_sub:\n",
    "            if each not in ['PetID']:\n",
    "                feature_metadata_sub[each] = feature_metadata_sub[each].astype(float)\n",
    "        \n",
    "        \n",
    "        feature_metadata_sub = feature_metadata_sub.groupby(['PetID']).agg(['mean', 'sum'])\n",
    "        feature_metadata_sub.columns = ['{}_{}'.format(c[0], c[1].upper()) for c in feature_metadata_sub.columns.tolist()]  \n",
    "        feature_metadata_sub = feature_metadata_sub.reset_index()\n",
    "            \n",
    "        feature_metadata = feature_metadata.append(feature_metadata_sub)\n",
    "    return feature_metadata\n",
    "\n",
    "\n",
    "#\n",
    "    \n",
    "\n",
    "#for each in \n",
    "#train_feature_metadata = extract_metadata_feature('fffd78a11-1', 'train')\n",
    "\n",
    "#train_feature_metadata = Parallel(n_jobs=8, verbose=1)(\n",
    "#        delayed(extract_metadata_feature)(i, 'train') for i in train.PetID)\n",
    "#train_feature_metadata = [x for x in train_feature_metadata]\n",
    "#train_feature_metadata = pd.concat(train_feature_metadata, ignore_index=True, sort=False)\n",
    "\n",
    "#test_feature_metadata = Parallel(n_jobs=8, verbose=1)(\n",
    "#        delayed(extract_metadata_feature)(i, 'test') for i in test.PetID)\n",
    "#test_feature_metadata = [x for x in test_feature_metadata]\n",
    "#test_feature_metadata = pd.concat(test_feature_metadata, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 连接sentiment和metadata和原始数据\n",
    "x_train = df_train.merge(train_feature_sentiment, how='left', on='PetID')\n",
    "#x_train = x_train.merge(train_feature_metadata, how='left', on='PetID')\n",
    "\n",
    "y_train = x_train['AdoptionSpeed']\n",
    "x_train.drop(['AdoptionSpeed'], axis=1, inplace=True)\n",
    "\n",
    "x_test = df_test.merge(test_feature_sentiment, how='left', on='PetID')\n",
    "#x_test = x_test.merge(test_feature_metadata, how='left', on='PetID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import SparsePCA, TruncatedSVD, LatentDirichletAllocation, NMF\n",
    "\n",
    "col_text = ['Description', 'annots_top_desc']\n",
    "\n",
    "x = x_train.append(x_test).reset_index()\n",
    "x = x[['Description', 'PetID', 'annots_top_desc']]\n",
    "\n",
    "n_components = 5\n",
    "\n",
    "x[col_text] = x[col_text].fillna('MISSING')\n",
    "text_features = []\n",
    "\n",
    "\n",
    "for i in col_text:\n",
    "    svd_ = TruncatedSVD(n_components=n_components)\n",
    "    nmf_ = NMF(n_components=n_components)\n",
    "    \n",
    "    tfidf_col = TfidfVectorizer(min_df=3, max_df=0.9).fit_transform(x.loc[:, i])\n",
    "\n",
    "    \n",
    "    svd_col = svd_.fit_transform(tfidf_col)\n",
    "    svd_col = pd.DataFrame(svd_col)\n",
    "    svd_col = svd_col.add_prefix('SVD_{}_'.format(i))\n",
    "    \n",
    "    nmf_col = nmf_.fit_transform(tfidf_col)\n",
    "    nmf_col = pd.DataFrame(nmf_col)\n",
    "    nmf_col = nmf_col.add_prefix('NMF_{}_'.format(i))\n",
    "\n",
    "    text_features.append(svd_col)\n",
    "    text_features.append(nmf_col)\n",
    "    \n",
    "    x.drop(i, axis=1, inplace=True)\n",
    "    \n",
    "# Combine all extracted features:\n",
    "text_features = pd.concat(text_features, axis=1)\n",
    "\n",
    "# Concatenate with main DF:\n",
    "x = pd.concat([x, text_features], axis=1)\n",
    "\n",
    "x_train = x_train.merge(x, how='left', on='PetID')\n",
    "x_test  = x_test.merge(x, how='left', on='PetID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 增加新的特征\n",
    "1、是否需要收费\n",
    "2、年份\n",
    "3、Color的笛卡尔积（效果不要）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train['IsFree'] = x_train['Fee'].apply(lambda x:1 if x>0 else 0)\n",
    "x_test['IsFree']  = x_test['Fee'].apply(lambda x:1 if x>0 else 0)\n",
    "\n",
    "x_train['Year'] = x_train['Age'].apply(lambda x:round(x/12))\n",
    "x_test['Year']  = x_test['Age'].apply(lambda x:round(x/12))\n",
    "\n",
    "x = x_train.append(x_test)\n",
    "x['Age_qcut'] = pd.qcut(x['Age'], 5,  duplicates='drop')\n",
    "x['Age_qcut'] = pd.factorize(x['Age_qcut'])[0]\n",
    "x_train = x_train.merge(x[['PetID','Age_qcut']], how='left', on='PetID')\n",
    "x_test  = x_test.merge(x[['PetID','Age_qcut']], how='left', on='PetID')\n",
    "\n",
    "#效果不好\n",
    "#x_train['Color_Mix'] = x_train['Color1'].astype(str)+x_train['Color2'].astype(str)+x_train['Color3'].astype(str)\n",
    "#x_train['Color_Mix'] = pd.factorize(x_train['Color_Mix'])[0]\n",
    "#x_test['Color_Mix'] = x_test['Color1'].astype(str)+x_test['Color2'].astype(str)+x_test['Color3'].astype(str)\n",
    "#x_test['Color_Mix'] = pd.factorize(x_test['Color_Mix'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RescuerID 处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "#%% RescuerID 处理\n",
    "\n",
    "df = df_train.append(df_test)\n",
    "data_rescuer = df.groupby(['RescuerID'])['PetID'].count().reset_index()\n",
    "data_rescuer.columns = ['RescuerID', 'RescuerID_count']\n",
    "#data_rescuer['rank_Rescuer_count'] = data_rescuer['RescuerID_count'].rank(pct=True)\n",
    "\n",
    "x_train = x_train.merge(data_rescuer, how='left', on='RescuerID')\n",
    "x_test  = x_test.merge(data_rescuer, how='left', on='RescuerID')\n",
    "\n",
    "#x_train.drop(['RescuerID_count'], axis=1, inplace=True)\n",
    "#x_test.drop(['RescuerID_count'], axis=1, inplace=True)\n",
    "\n",
    "x_train['single'] = x_train['RescuerID_count'].apply(lambda x:1 if x<3 else 0)\n",
    "x_train['middle'] = x_train['RescuerID_count'].apply(lambda x:1 if (x>2 and x<6) else 0)\n",
    "x_train['Charities'] = x_train['RescuerID_count'].apply(lambda x:1 if x>5 else 0)\n",
    "\n",
    "x_test['single'] = x_test['RescuerID_count'].apply(lambda x:1 if x<3 else 0)\n",
    "x_test['middle'] = x_test['RescuerID_count'].apply(lambda x:1 if (x>2 and x<6) else 0)\n",
    "x_test['Charities'] = x_test['RescuerID_count'].apply(lambda x:1 if x>5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([146,   4,  14,  81,   1,   7,  37,  15,   2,  18,  10,  64,   3,\n",
       "        49,   5,   6,   9,  67,   8,  12,  26,  62,  11,  27,  22,  34,\n",
       "        25,  74,  48,  31,  59,  16,  54,  23,  21,  35,  17,  43,  19,\n",
       "        13])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test['RescuerID_count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train['single'] = x_train['RescuerID_count'].apply(lambda x:1 if x<3 else 0)\n",
    "x_train['middle'] = x_train['RescuerID_count'].apply(lambda x:1 if (x>2 and x<6) else 0)\n",
    "x_train['Charities'] = x_train['RescuerID_count'].apply(lambda x:1 if x>5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>NMF_token_2</th>\n",
       "      <th>NMF_token_3</th>\n",
       "      <th>NMF_token_4</th>\n",
       "      <th>IsFree</th>\n",
       "      <th>Year</th>\n",
       "      <th>Age_qcut</th>\n",
       "      <th>RescuerID_count</th>\n",
       "      <th>single</th>\n",
       "      <th>middle</th>\n",
       "      <th>Charities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028520</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024119</td>\n",
       "      <td>0.018522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.012173</td>\n",
       "      <td>0.036687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067366</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033239</td>\n",
       "      <td>0.007047</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.080696</td>\n",
       "      <td>0.011082</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>BULAT</td>\n",
       "      <td>12</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041352</td>\n",
       "      <td>0.013317</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Siu Pak &amp; Her 6 Puppies</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.022216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.024057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Kitty</td>\n",
       "      <td>12</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Bear</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Kali</td>\n",
       "      <td>3</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.041782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Peanut</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2 Mths Old Cute Kitties</td>\n",
       "      <td>2</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.084207</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>Lost Dog</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>Max</td>\n",
       "      <td>78</td>\n",
       "      <td>218</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>Brownie</td>\n",
       "      <td>6</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Blackie</td>\n",
       "      <td>8</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013471</td>\n",
       "      <td>0.013536</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>Godiva</td>\n",
       "      <td>12</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>0.032844</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>Tigers</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>Kenit, Kenot, Techit, Keyad, Owen</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.045963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>Donut</td>\n",
       "      <td>10</td>\n",
       "      <td>307</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.016261</td>\n",
       "      <td>0.019189</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>Cikenet</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>Garfield</td>\n",
       "      <td>36</td>\n",
       "      <td>285</td>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name</td>\n",
       "      <td>2</td>\n",
       "      <td>285</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015394</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036370</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>14</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045865</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>Pepper</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035554</td>\n",
       "      <td>0.039251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14958</th>\n",
       "      <td>2</td>\n",
       "      <td>Boceyyy</td>\n",
       "      <td>6</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14959</th>\n",
       "      <td>2</td>\n",
       "      <td>Panbe</td>\n",
       "      <td>36</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14960</th>\n",
       "      <td>2</td>\n",
       "      <td>Manis</td>\n",
       "      <td>2</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020083</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14961</th>\n",
       "      <td>2</td>\n",
       "      <td>Belang</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.030344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14962</th>\n",
       "      <td>2</td>\n",
       "      <td>Doremon</td>\n",
       "      <td>24</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077906</td>\n",
       "      <td>0.015521</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14963</th>\n",
       "      <td>2</td>\n",
       "      <td>Sentul Kittiens</td>\n",
       "      <td>2</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.020506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14964</th>\n",
       "      <td>2</td>\n",
       "      <td>Tommie</td>\n",
       "      <td>10</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051924</td>\n",
       "      <td>0.050884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14965</th>\n",
       "      <td>1</td>\n",
       "      <td>KL Puppies For Adoption</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.015574</td>\n",
       "      <td>0.090408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14966</th>\n",
       "      <td>2</td>\n",
       "      <td>Omari</td>\n",
       "      <td>5</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077248</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14967</th>\n",
       "      <td>2</td>\n",
       "      <td>Kofi (annan)</td>\n",
       "      <td>2</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14968</th>\n",
       "      <td>1</td>\n",
       "      <td>Zee4</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14969</th>\n",
       "      <td>1</td>\n",
       "      <td>Ang Ang</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.103639</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14970</th>\n",
       "      <td>1</td>\n",
       "      <td>Wormmy</td>\n",
       "      <td>24</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173664</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14971</th>\n",
       "      <td>2</td>\n",
       "      <td>Cici N Shelly</td>\n",
       "      <td>84</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14972</th>\n",
       "      <td>2</td>\n",
       "      <td>Kimchi</td>\n",
       "      <td>3</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>0.015253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14973</th>\n",
       "      <td>1</td>\n",
       "      <td>Ethio</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.073650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14974</th>\n",
       "      <td>1</td>\n",
       "      <td>SambaBoy</td>\n",
       "      <td>6</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034078</td>\n",
       "      <td>0.005639</td>\n",
       "      <td>0.046820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14975</th>\n",
       "      <td>1</td>\n",
       "      <td>Bella</td>\n",
       "      <td>24</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14976</th>\n",
       "      <td>1</td>\n",
       "      <td>Patch</td>\n",
       "      <td>8</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067250</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14977</th>\n",
       "      <td>2</td>\n",
       "      <td>âªMami's Babies âª</td>\n",
       "      <td>2</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030157</td>\n",
       "      <td>0.067735</td>\n",
       "      <td>0.013399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14978</th>\n",
       "      <td>1</td>\n",
       "      <td>Alger</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14979</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14980</th>\n",
       "      <td>1</td>\n",
       "      <td>Terry</td>\n",
       "      <td>24</td>\n",
       "      <td>179</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14981</th>\n",
       "      <td>2</td>\n",
       "      <td>Pets + Strays : BlueEyed BlackWhite</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>0.013199</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14982</th>\n",
       "      <td>1</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>6</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>0.096688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14984</th>\n",
       "      <td>2</td>\n",
       "      <td>Serato &amp; Eddie</td>\n",
       "      <td>60</td>\n",
       "      <td>265</td>\n",
       "      <td>264</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14985</th>\n",
       "      <td>2</td>\n",
       "      <td>Monkies</td>\n",
       "      <td>2</td>\n",
       "      <td>265</td>\n",
       "      <td>266</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.035823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14986</th>\n",
       "      <td>2</td>\n",
       "      <td>Ms Daym</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14987</th>\n",
       "      <td>1</td>\n",
       "      <td>Fili</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14988 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type                                 Name  Age  Breed1  Breed2  Gender  \\\n",
       "0         2                               Nibble    3     299       0       1   \n",
       "1         2                          No Name Yet    1     265       0       1   \n",
       "2         1                               Brisco    1     307       0       1   \n",
       "3         1                                 Miko    4     307       0       2   \n",
       "4         1                               Hunter    1     307       0       1   \n",
       "5         2                                  NaN    3     266       0       2   \n",
       "6         2                                BULAT   12     264     264       1   \n",
       "7         1              Siu Pak & Her 6 Puppies    0     307       0       2   \n",
       "8         2                                  NaN    2     265       0       2   \n",
       "9         2                                Kitty   12     265       0       2   \n",
       "10        1                                 Bear    2     307       0       1   \n",
       "11        2                                 Kali    3     264       0       2   \n",
       "12        1                               Peanut    2     307       0       1   \n",
       "13        2              2 Mths Old Cute Kitties    2     265       0       3   \n",
       "14        1                             Lost Dog    3     307       0       2   \n",
       "15        1                                  Max   78     218     205       1   \n",
       "16        2                              Brownie    6     266       0       2   \n",
       "17        1                              Blackie    8     307     307       2   \n",
       "18        1                               Beauty    2     307       0       2   \n",
       "19        2                                  NaN    1     266       0       3   \n",
       "20        1                               Godiva   12     307       0       2   \n",
       "21        1                               Tigers    3     307       0       2   \n",
       "22        2    Kenit, Kenot, Techit, Keyad, Owen    0     114       0       3   \n",
       "23        1                                Donut   10     307     117       2   \n",
       "24        2                              Cikenet    3     266       0       1   \n",
       "25        2                             Garfield   36     285     251       1   \n",
       "26        2                              No Name    2     285     265       1   \n",
       "27        2                              No Name    1     266       0       2   \n",
       "28        1                               Hunter   14     189       0       1   \n",
       "29        2                               Pepper    1     266       0       2   \n",
       "...     ...                                  ...  ...     ...     ...     ...   \n",
       "14958     2                              Boceyyy    6     276       0       1   \n",
       "14959     2                                Panbe   36     265       0       1   \n",
       "14960     2                                Manis    2     266       0       2   \n",
       "14961     2                               Belang    1     265       0       1   \n",
       "14962     2                              Doremon   24     265       0       2   \n",
       "14963     2                      Sentul Kittiens    2     266       0       3   \n",
       "14964     2                               Tommie   10     266       0       1   \n",
       "14965     1              KL Puppies For Adoption    2     307       0       2   \n",
       "14966     2                                Omari    5     265       0       1   \n",
       "14967     2                         Kofi (annan)    2     266       0       1   \n",
       "14968     1                                 Zee4    2     307     307       2   \n",
       "14969     1                              Ang Ang    2     307       0       1   \n",
       "14970     1                               Wormmy   24     307       0       2   \n",
       "14971     2                        Cici N Shelly   84     264     264       3   \n",
       "14972     2                               Kimchi    3     254       0       2   \n",
       "14973     1                                Ethio    4     307       0       2   \n",
       "14974     1                             SambaBoy    6     307       0       1   \n",
       "14975     1                                Bella   24     307     307       2   \n",
       "14976     1                                Patch    8     307       0       2   \n",
       "14977     2                 âªMami's Babies âª    2     266       0       2   \n",
       "14978     1                                Alger    3     307       0       1   \n",
       "14979     1                                  NaN   60     307       0       2   \n",
       "14980     1                                Terry   24     179     307       1   \n",
       "14981     2  Pets + Strays : BlueEyed BlackWhite    1     266       0       2   \n",
       "14982     1                                Snowy    6     195       0       2   \n",
       "14983     2                                  NaN    2     266       0       3   \n",
       "14984     2                       Serato & Eddie   60     265     264       3   \n",
       "14985     2                              Monkies    2     265     266       3   \n",
       "14986     2                              Ms Daym    9     266       0       2   \n",
       "14987     1                                 Fili    1     307     307       1   \n",
       "\n",
       "       Color1  Color2  Color3  MaturitySize    ...      NMF_token_2  \\\n",
       "0           1       7       0             1    ...         0.000000   \n",
       "1           1       2       0             2    ...         0.000000   \n",
       "2           2       7       0             2    ...         0.000956   \n",
       "3           1       2       0             2    ...         0.000774   \n",
       "4           1       0       0             2    ...         0.033239   \n",
       "5           5       6       0             2    ...         0.001423   \n",
       "6           1       0       0             2    ...         0.000000   \n",
       "7           1       2       7             2    ...         0.003908   \n",
       "8           6       0       0             2    ...         0.000887   \n",
       "9           1       7       0             2    ...         0.000000   \n",
       "10          1       2       7             2    ...         0.002537   \n",
       "11          1       2       5             3    ...         0.001388   \n",
       "12          2       5       6             2    ...         0.002060   \n",
       "13          1       6       7             1    ...         0.002061   \n",
       "14          2       5       7             2    ...         0.000339   \n",
       "15          1       7       0             2    ...         0.000000   \n",
       "16          2       0       0             1    ...         0.000000   \n",
       "17          2       0       0             2    ...         0.000000   \n",
       "18          1       0       0             2    ...         0.000000   \n",
       "19          1       2       7             1    ...         0.000000   \n",
       "20          2       7       0             2    ...         0.000000   \n",
       "21          6       0       0             2    ...         0.007214   \n",
       "22          3       6       7             2    ...         0.000809   \n",
       "23          1       2       7             2    ...         0.002098   \n",
       "24          2       7       0             1    ...         0.000000   \n",
       "25          3       0       0             3    ...         0.000000   \n",
       "26          3       0       0             2    ...         0.000000   \n",
       "27          1       0       0             2    ...         0.000000   \n",
       "28          1       2       0             3    ...         0.000000   \n",
       "29          2       7       0             1    ...         0.035554   \n",
       "...       ...     ...     ...           ...    ...              ...   \n",
       "14958       1       0       0             2    ...         0.000000   \n",
       "14959       6       7       0             2    ...         0.000000   \n",
       "14960       1       0       0             1    ...         0.000000   \n",
       "14961       1       2       0             1    ...         0.002444   \n",
       "14962       2       4       0             1    ...         0.000000   \n",
       "14963       3       7       0             2    ...         0.001675   \n",
       "14964       1       7       0             2    ...         0.051924   \n",
       "14965       2       5       0             2    ...         0.006027   \n",
       "14966       3       7       0             3    ...         0.000000   \n",
       "14967       6       0       0             2    ...         0.000000   \n",
       "14968       2       7       0             2    ...         0.248001   \n",
       "14969       1       2       7             2    ...         0.000000   \n",
       "14970       2       7       0             2    ...         0.000000   \n",
       "14971       1       7       0             2    ...         0.000000   \n",
       "14972       1       2       7             1    ...         0.000000   \n",
       "14973       2       0       0             2    ...         0.001957   \n",
       "14974       1       7       0             2    ...         0.034078   \n",
       "14975       2       0       0             3    ...         0.000000   \n",
       "14976       2       7       0             2    ...         0.067250   \n",
       "14977       1       4       7             2    ...         0.030157   \n",
       "14978       1       2       7             2    ...         0.000000   \n",
       "14979       2       5       0             2    ...         0.000000   \n",
       "14980       2       3       7             2    ...         0.000000   \n",
       "14981       5       6       7             2    ...         0.020020   \n",
       "14982       1       7       0             1    ...         0.000000   \n",
       "14983       1       0       0             2    ...         0.003437   \n",
       "14984       1       4       7             2    ...         0.000000   \n",
       "14985       5       6       7             3    ...         0.003040   \n",
       "14986       4       7       0             1    ...         0.000224   \n",
       "14987       2       0       0             2    ...         0.000195   \n",
       "\n",
       "       NMF_token_3  NMF_token_4  IsFree  Year  Age_qcut  RescuerID_count  \\\n",
       "0         0.028520     0.005579       1     0         0                8   \n",
       "1         0.024119     0.018522       0     0         1                1   \n",
       "2         0.012173     0.036687       0     0         1              459   \n",
       "3         0.000000     0.067366       1     0         2               50   \n",
       "4         0.007047     0.013453       0     0         1              134   \n",
       "5         0.080696     0.011082       0     0         0                4   \n",
       "6         0.041352     0.013317       1     1         3               10   \n",
       "7         0.004248     0.022216       0     0         1                3   \n",
       "8         0.024057     0.000000       0     0         1                7   \n",
       "9         0.077242     0.000000       0     1         3                1   \n",
       "10        0.009023     0.005782       0     0         1               50   \n",
       "11        0.041782     0.000000       1     0         0                6   \n",
       "12        0.000000     0.001607       0     0         1               52   \n",
       "13        0.084207     0.004415       0     0         1                2   \n",
       "14        0.000000     0.017015       0     0         0                1   \n",
       "15        0.005790     0.003290       0     6         4                1   \n",
       "16        0.000000     0.000000       0     0         3                4   \n",
       "17        0.000000     0.042400       1     1         3                1   \n",
       "18        0.013471     0.013536       0     0         1               50   \n",
       "19        0.000000     0.000000       0     0         1                2   \n",
       "20        0.003313     0.032844       0     1         3               95   \n",
       "21        0.000000     0.036071       0     0         0                4   \n",
       "22        0.045963     0.000000       0     0         1                1   \n",
       "23        0.016261     0.019189       0     1         3              315   \n",
       "24        0.043642     0.000000       0     0         0               11   \n",
       "25        0.082491     0.000000       0     3         4               61   \n",
       "26        0.015394     0.003428       0     0         1                1   \n",
       "27        0.036370     0.013617       0     0         1                3   \n",
       "28        0.000000     0.045865       1     1         4                2   \n",
       "29        0.039251     0.000000       0     0         1               11   \n",
       "...            ...          ...     ...   ...       ...              ...   \n",
       "14958     0.071865     0.000000       1     0         3                2   \n",
       "14959     0.086096     0.000000       0     3         4                1   \n",
       "14960     0.020083     0.000580       0     0         1                1   \n",
       "14961     0.030344     0.000000       0     0         1               26   \n",
       "14962     0.077906     0.015521       0     2         4                5   \n",
       "14963     0.020506     0.000000       1     0         1               39   \n",
       "14964     0.050884     0.000000       0     1         3                8   \n",
       "14965     0.015574     0.090408       0     0         1                4   \n",
       "14966     0.077248     0.006334       0     0         2                3   \n",
       "14967     0.023393     0.000000       0     0         1              156   \n",
       "14968     0.000000     0.000000       0     0         1              228   \n",
       "14969     0.005165     0.103639       0     0         1                4   \n",
       "14970     0.000000     0.173664       0     2         4               93   \n",
       "14971     0.000000     0.000000       1     7         4                1   \n",
       "14972     0.009115     0.015253       0     0         0                1   \n",
       "14973     0.002256     0.073650       0     0         2              231   \n",
       "14974     0.005639     0.046820       0     0         3               74   \n",
       "14975     0.004172     0.001350       0     2         4                1   \n",
       "14976     0.001965     0.001834       0     1         3               61   \n",
       "14977     0.067735     0.013399       0     0         1               23   \n",
       "14978     0.000000     0.000000       0     0         0              459   \n",
       "14979     0.000000     0.000000       0     5         4                4   \n",
       "14980     0.002881     0.000000       0     2         4                5   \n",
       "14981     0.013199     0.000634       0     0         1               34   \n",
       "14982     0.000000     0.000000       0     0         3                1   \n",
       "14983     0.096688     0.000000       0     0         1                4   \n",
       "14984     0.009994     0.000000       0     5         4                3   \n",
       "14985     0.035823     0.000000       1     0         1               19   \n",
       "14986     0.000209     0.000254       0     1         3                5   \n",
       "14987     0.000404     0.001148       0     0         1                6   \n",
       "\n",
       "       single middle  Charities  \n",
       "0           0      0          1  \n",
       "1           1      0          0  \n",
       "2           0      0          1  \n",
       "3           0      0          1  \n",
       "4           0      0          1  \n",
       "5           0      1          0  \n",
       "6           0      0          1  \n",
       "7           0      1          0  \n",
       "8           0      0          1  \n",
       "9           1      0          0  \n",
       "10          0      0          1  \n",
       "11          0      0          1  \n",
       "12          0      0          1  \n",
       "13          1      0          0  \n",
       "14          1      0          0  \n",
       "15          1      0          0  \n",
       "16          0      1          0  \n",
       "17          1      0          0  \n",
       "18          0      0          1  \n",
       "19          1      0          0  \n",
       "20          0      0          1  \n",
       "21          0      1          0  \n",
       "22          1      0          0  \n",
       "23          0      0          1  \n",
       "24          0      0          1  \n",
       "25          0      0          1  \n",
       "26          1      0          0  \n",
       "27          0      1          0  \n",
       "28          1      0          0  \n",
       "29          0      0          1  \n",
       "...       ...    ...        ...  \n",
       "14958       1      0          0  \n",
       "14959       1      0          0  \n",
       "14960       1      0          0  \n",
       "14961       0      0          1  \n",
       "14962       0      1          0  \n",
       "14963       0      0          1  \n",
       "14964       0      0          1  \n",
       "14965       0      1          0  \n",
       "14966       0      1          0  \n",
       "14967       0      0          1  \n",
       "14968       0      0          1  \n",
       "14969       0      1          0  \n",
       "14970       0      0          1  \n",
       "14971       1      0          0  \n",
       "14972       1      0          0  \n",
       "14973       0      0          1  \n",
       "14974       0      0          1  \n",
       "14975       1      0          0  \n",
       "14976       0      0          1  \n",
       "14977       0      0          1  \n",
       "14978       0      0          1  \n",
       "14979       0      1          0  \n",
       "14980       0      1          0  \n",
       "14981       0      0          1  \n",
       "14982       1      0          0  \n",
       "14983       0      1          0  \n",
       "14984       0      1          0  \n",
       "14985       0      0          1  \n",
       "14986       0      1          0  \n",
       "14987       0      0          1  \n",
       "\n",
       "[14988 rows x 55 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[['single', 'middle', 'Charities', 'RescuerID_count']]\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理Breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14988, 60) (3948, 60)\n"
     ]
    }
   ],
   "source": [
    "x_train['HasSecondBreed'] = x_train['Breed2'].map(lambda x:1 if x != 0 else 0)\n",
    "x_test['HasSecondBreed'] = x_test['Breed2'].map(lambda x:1 if x != 0 else 0)\n",
    "\n",
    "train_breed_main = x_train[['Breed1']].merge(\n",
    "    labels_breed, how='left',\n",
    "    left_on='Breed1', right_on='BreedID',\n",
    "    suffixes=('', '_main_breed'))\n",
    "\n",
    "train_breed_main = train_breed_main.iloc[:, 2:]\n",
    "train_breed_main = train_breed_main.add_prefix('main_breed_')\n",
    "\n",
    "train_breed_second = x_train[['Breed2']].merge(\n",
    "    labels_breed, how='left',\n",
    "    left_on='Breed2', right_on='BreedID',\n",
    "    suffixes=('', '_second_breed'))\n",
    "\n",
    "\n",
    "train_breed_second = train_breed_second.iloc[:, 2:]\n",
    "train_breed_second = train_breed_second.add_prefix('second_breed_')\n",
    "\n",
    "x_train = pd.concat(\n",
    "    [x_train, train_breed_main, train_breed_second], axis=1)\n",
    "\n",
    "##############\n",
    "test_breed_main = x_test[['Breed1']].merge(\n",
    "    labels_breed, how='left',\n",
    "    left_on='Breed1', right_on='BreedID',\n",
    "    suffixes=('', '_main_breed'))\n",
    "\n",
    "test_breed_main = test_breed_main.iloc[:, 2:]\n",
    "test_breed_main = test_breed_main.add_prefix('main_breed_')\n",
    "\n",
    "test_breed_second = x_test[['Breed2']].merge(\n",
    "    labels_breed, how='left',\n",
    "    left_on='Breed2', right_on='BreedID',\n",
    "    suffixes=('', '_second_breed'))\n",
    "\n",
    "test_breed_second = test_breed_second.iloc[:, 2:]\n",
    "test_breed_second = test_breed_second.add_prefix('second_breed_')\n",
    "\n",
    "x_test = pd.concat(\n",
    "    [x_test, test_breed_main, test_breed_second], axis=1)\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "categorical_columns = ['main_breed_BreedName', 'second_breed_BreedName']\n",
    "for i in categorical_columns:\n",
    "    x_train.loc[:, i] = pd.factorize(x_train.loc[:, i])[0]\n",
    "    x_test.loc[:,i]   = pd.factorize(x_test.loc[:, i])[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 等某些特征进行rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 对某些特征进行rank\n",
    "cols_rank = ['sentence_magnitude', 'sentence_score', 'document_magnitude','document_score']#,\n",
    "#       'annots_score_MEAN', 'annots_score_SUM','color_score_MEAN', 'color_score_SUM', 'color_pixelfrac_MEAN',\n",
    "#       'color_pixelfrac_SUM', 'crop_conf_MEAN', 'crop_conf_SUM','crop_importance_MEAN', 'crop_importance_SUM']\n",
    "\n",
    "x = x_train.append(x_test)\n",
    "x[cols_rank] = x[cols_rank].fillna(0)\n",
    "df_cols_rank = x[cols_rank].rank(pct=True).rename(columns=lambda s:'rank.'+s)\n",
    "df_cols_rank = pd.concat([df_cols_rank, x['PetID']], axis=1)\n",
    "\n",
    "x_train = x_train.merge(df_cols_rank, how='left', on='PetID')\n",
    "x_test =  x_test.merge(df_cols_rank, how='left', on='PetID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Name', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
       "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
       "       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID',\n",
       "       'VideoAmt', 'Description', 'PetID', 'PhotoAmt', 'token',\n",
       "       'sentence_magnitude', 'sentence_score', 'document_magnitude',\n",
       "       'document_score', 'SVD_Description_0', 'SVD_Description_1',\n",
       "       'SVD_Description_2', 'SVD_Description_3', 'SVD_Description_4',\n",
       "       'NMF_Description_0', 'NMF_Description_1', 'NMF_Description_2',\n",
       "       'NMF_Description_3', 'NMF_Description_4', 'SVD_token_0', 'SVD_token_1',\n",
       "       'SVD_token_2', 'SVD_token_3', 'SVD_token_4', 'NMF_token_0',\n",
       "       'NMF_token_1', 'NMF_token_2', 'NMF_token_3', 'NMF_token_4', 'IsFree',\n",
       "       'Year', 'Age_qcut', 'RescuerID_count', 'HasSecondBreed',\n",
       "       'main_breed_Type', 'main_breed_BreedName', 'second_breed_Type',\n",
       "       'second_breed_BreedName', 'rank.sentence_magnitude',\n",
       "       'rank.sentence_score', 'rank.document_magnitude',\n",
       "       'rank.document_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['Name', 'RescuerID', 'Description', 'PetID', 'token']\n",
    "col = ['sentence_magnitude', 'sentence_score', 'document_magnitude', 'document_score']\n",
    "\n",
    "x_train.drop(drop_columns, axis=1, inplace=True)\n",
    "x_test.drop(drop_columns, axis=1, inplace=True)\n",
    "\n",
    "x_train[col] = x_train[col].astype(float)\n",
    "x_test[col]  = x_test[col].astype(float)\n",
    "\n",
    "x_train = x_train.fillna(0)\n",
    "x_test  = x_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGB 算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "       eval_metric='scorer', importance_type='split', learning_rate=0.01,\n",
       "       max_depth=5, min_child_samples=5, min_child_weight=0.001,\n",
       "       min_split_gain=0.0, n_estimators=2000, n_jobs=-1, num_leaves=30,\n",
       "       objective='regression', random_state=4, reg_alpha=0.0,\n",
       "       reg_lambda=0.0, silent=True, subsample=0.7,\n",
       "       subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm.sklearn import LGBMRegressor\n",
    "\n",
    "\n",
    "model_lgb = LGBMRegressor(\n",
    "        learning_rate    = 0.01,\n",
    "        n_estimators     = 2000,\n",
    "        max_depth        = 5,\n",
    "        num_leaves       = 30,\n",
    "        subsample        = 0.7,      #训练时采样一定比例的数据\t\n",
    "        colsample_bytree = 0.7,\n",
    "        n_jobs           = -1,\n",
    "        random_state     = 4,\n",
    "        objective        = 'regression',\n",
    "        eval_metric      = 'scorer',\n",
    "        min_child_samples = 5         #叶子节点具有的最小记录数\t\n",
    "\n",
    "        )\n",
    "        \n",
    "model_lgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 568, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 605, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 635, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/scorer.py\", line 98, in __call__\n    **self._kwargs)\n  File \"<ipython-input-319-58e377756040>\", line 4, in metric\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\", line 354, in cohen_kappa_score\n    sample_weight=sample_weight)\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\", line 253, in confusion_matrix\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\", line 81, in _check_targets\n    \"and {1} targets\".format(type_true, type_pred))\nValueError: Classification metrics can't handle a mix of multiclass and continuous targets\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-353-4f73546c81cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgsearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_lgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mgsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "#调参\n",
    "parameters = {\n",
    "            'reg_alpha': [0,0.01,0.1,1],\n",
    "            'reg_lambda': [0,0.01,0.1,1]\n",
    "            }\n",
    "\n",
    "gsearch = GridSearchCV(model_lgb, param_grid=parameters, scoring=scorer, cv=10, n_jobs=-1)\n",
    "gsearch.fit(x_train, y_train)\n",
    "gsearch.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM多分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovo', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import sklearn.svm as svm \n",
    "\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不分组预测0.25924689193170236\n"
     ]
    }
   ],
   "source": [
    "y_pre = model_lgb.predict(x_train)\n",
    "#y_pre = np.round(y_pre)\n",
    "val = cross_val_score(clf, x_train, y_train, scoring = scorer, cv=10).mean()\n",
    "print('不分组预测{}'.format(val))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=0.4, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_rf = RandomForestRegressor(\n",
    "    n_estimators      = 200,\n",
    "    \n",
    "    max_features      = 0.4,#选择最适属性时划分的特征不能超过此值。\n",
    "#    max_depth         = 6, #设置树的最大深度，默认为None\n",
    "    \n",
    "    min_samples_leaf  = 1, #叶子节点最少的样本数\n",
    "    min_samples_split = 2,#根据属性划分节点时，每个划分最少的样本数\n",
    "    \n",
    "    criterion = 'mse',\n",
    "    \n",
    "    n_jobs            = -1\n",
    "    )\n",
    "\n",
    "model_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "model_xgb = XGBRegressor(\n",
    "    learning_rate    = 0.05,\n",
    "    n_estimatores    = 2000, \n",
    "    \n",
    "    early_stopping_rounds=20,  \n",
    "    \n",
    "    max_depth        = 10, \n",
    "    min_child_weight = 5,\n",
    "    \n",
    "    gamma            = 0,\n",
    "    \n",
    "    subsample        =  0.9,\n",
    "    colsample_bytree = 0.6,\n",
    "    \n",
    "#    reg_alpha        = 3,\n",
    "#    reg_lambda       = 0.1,\n",
    "    nthread      = -1)\n",
    "#    objective        = 'regression',    \n",
    "#    eval_metric      = 'scorer')      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 12, 'min_child_weight': 11}"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#调参\n",
    "parameters = {'max_depth': range(6,14,2), 'min_child_weight': range(3,13,2)}\n",
    "gsearch = GridSearchCV(model_xgb, param_grid=parameters, scoring=scorer, cv=10, n_jobs=-1)\n",
    "gsearch.fit(x_train, y_train)\n",
    "gsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 后处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop('Resc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10折后的Kappa加权得分为:带补充\n",
      "basinhopping step 0: f -0.439404\n",
      "basinhopping step 1: f -0.439423 trial_f -0.439423 accepted 1  lowest_f -0.439423\n",
      "found new global minimum on step 1 with function value -0.439423\n",
      "basinhopping step 2: f -0.439474 trial_f -0.439474 accepted 1  lowest_f -0.439474\n",
      "found new global minimum on step 2 with function value -0.439474\n",
      "basinhopping step 3: f -0.438211 trial_f -0.438211 accepted 1  lowest_f -0.439474\n",
      "basinhopping step 4: f -0.439639 trial_f -0.439639 accepted 1  lowest_f -0.439639\n",
      "found new global minimum on step 4 with function value -0.439639\n",
      "basinhopping step 5: f -0.439 trial_f -0.439 accepted 1  lowest_f -0.439639\n",
      "basinhopping step 6: f -0.43943 trial_f -0.43943 accepted 1  lowest_f -0.439639\n",
      "basinhopping step 7: f -0.43916 trial_f -0.43916 accepted 1  lowest_f -0.439639\n",
      "basinhopping step 8: f -0.439851 trial_f -0.439851 accepted 1  lowest_f -0.439851\n",
      "found new global minimum on step 8 with function value -0.439851\n",
      "basinhopping step 9: f -0.439707 trial_f -0.439707 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 10: f -0.438453 trial_f -0.438453 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 11: f -0.439691 trial_f -0.439691 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 12: f -0.43933 trial_f -0.43933 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 13: f -0.43927 trial_f -0.43927 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 14: f -0.438131 trial_f -0.438131 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 15: f -0.43906 trial_f -0.43906 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 16: f -0.438924 trial_f -0.438924 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 17: f -0.439261 trial_f -0.439261 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 18: f -0.438072 trial_f -0.438072 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 19: f -0.438522 trial_f -0.438522 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 20: f -0.438924 trial_f -0.438924 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 21: f -0.439295 trial_f -0.439295 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 22: f -0.439516 trial_f -0.439516 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 23: f -0.438272 trial_f -0.438272 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 24: f -0.439405 trial_f -0.439405 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 25: f -0.439161 trial_f -0.439161 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 26: f -0.439116 trial_f -0.439116 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 27: f -0.439389 trial_f -0.439389 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 28: f -0.43786 trial_f -0.43786 accepted 1  lowest_f -0.439851\n",
      "basinhopping step 29: f -0.440357 trial_f -0.440357 accepted 1  lowest_f -0.440357\n",
      "found new global minimum on step 29 with function value -0.440357\n",
      "basinhopping step 30: f -0.438525 trial_f -0.438525 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 31: f -0.438914 trial_f -0.438914 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 32: f -0.439458 trial_f -0.439458 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 33: f -0.439577 trial_f -0.439577 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 34: f -0.439993 trial_f -0.439993 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 35: f -0.439442 trial_f -0.439442 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 36: f -0.439089 trial_f -0.439089 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 37: f -0.439173 trial_f -0.439173 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 38: f -0.439285 trial_f -0.439285 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 39: f -0.438787 trial_f -0.438787 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 40: f -0.438223 trial_f -0.438223 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 41: f -0.439371 trial_f -0.439371 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 42: f -0.438484 trial_f -0.438484 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 43: f -0.43875 trial_f -0.43875 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 44: f -0.437454 trial_f -0.437454 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 45: f -0.439204 trial_f -0.439204 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 46: f -0.438015 trial_f -0.438015 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 47: f -0.438613 trial_f -0.438613 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 48: f -0.437163 trial_f -0.437163 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 49: f -0.438898 trial_f -0.438898 accepted 1  lowest_f -0.440357\n",
      "basinhopping step 50: f -0.439141 trial_f -0.439141 accepted 1  lowest_f -0.440357\n",
      "随机森林二次加权Kappa系数为: 0.44035715410508336\n"
     ]
    }
   ],
   "source": [
    "y_rf = split_score(model_rf, x_train, y_train)\n",
    "    \n",
    "coe = search_coef(y_rf, y_train)\n",
    "best_coe = coe['x']\n",
    "\n",
    "yy_rf = fix_y(y_rf, best_coe)\n",
    "print('随机森林二次加权Kappa系数为:', metric(yy_rf, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14988,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10折后的Kappa加权得分为:带补充\n",
      "lgb二次加权Kappa系数为: 0.4432320614037043\n"
     ]
    }
   ],
   "source": [
    "y_lgb = split_score(model_lgb, x_train, y_train)\n",
    "\n",
    "coe = search_coef(y_lgb, y_train)\n",
    "best_coe = coe['x']\n",
    "\n",
    "yy_lgb = fix_y(y_lgb, best_coe)\n",
    "print('lgb二次加权Kappa系数为:', metric(yy_lgb, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10折后的Kappa加权得分为:带补充\n",
      "basinhopping step 0: f -0.439899\n",
      "basinhopping step 1: f -0.440282 trial_f -0.440282 accepted 1  lowest_f -0.440282\n",
      "found new global minimum on step 1 with function value -0.440282\n",
      "basinhopping step 2: f -0.440457 trial_f -0.440457 accepted 1  lowest_f -0.440457\n",
      "found new global minimum on step 2 with function value -0.440457\n",
      "basinhopping step 3: f -0.439552 trial_f -0.439552 accepted 1  lowest_f -0.440457\n",
      "basinhopping step 4: f -0.439495 trial_f -0.439495 accepted 1  lowest_f -0.440457\n",
      "basinhopping step 5: f -0.440775 trial_f -0.440775 accepted 1  lowest_f -0.440775\n",
      "found new global minimum on step 5 with function value -0.440775\n",
      "basinhopping step 6: f -0.440836 trial_f -0.440836 accepted 1  lowest_f -0.440836\n",
      "found new global minimum on step 6 with function value -0.440836\n",
      "basinhopping step 7: f -0.440319 trial_f -0.440319 accepted 1  lowest_f -0.440836\n",
      "basinhopping step 8: f -0.440774 trial_f -0.440774 accepted 1  lowest_f -0.440836\n",
      "basinhopping step 9: f -0.440508 trial_f -0.440508 accepted 1  lowest_f -0.440836\n",
      "basinhopping step 10: f -0.440144 trial_f -0.440144 accepted 1  lowest_f -0.440836\n",
      "basinhopping step 11: f -0.4408 trial_f -0.4408 accepted 1  lowest_f -0.440836\n",
      "basinhopping step 12: f -0.439579 trial_f -0.439579 accepted 1  lowest_f -0.440836\n",
      "basinhopping step 13: f -0.43987 trial_f -0.43987 accepted 1  lowest_f -0.440836\n",
      "basinhopping step 14: f -0.440578 trial_f -0.440578 accepted 1  lowest_f -0.440836\n",
      "basinhopping step 15: f -0.439936 trial_f -0.439936 accepted 1  lowest_f -0.440836\n",
      "basinhopping step 16: f -0.440037 trial_f -0.440037 accepted 1  lowest_f -0.440836\n",
      "basinhopping step 17: f -0.440366 trial_f -0.440366 accepted 1  lowest_f -0.440836\n",
      "basinhopping step 18: f -0.440967 trial_f -0.440967 accepted 1  lowest_f -0.440967\n",
      "found new global minimum on step 18 with function value -0.440967\n",
      "basinhopping step 19: f -0.441924 trial_f -0.441924 accepted 1  lowest_f -0.441924\n",
      "found new global minimum on step 19 with function value -0.441924\n",
      "basinhopping step 20: f -0.441827 trial_f -0.441827 accepted 1  lowest_f -0.441924\n",
      "basinhopping step 21: f -0.441467 trial_f -0.441467 accepted 1  lowest_f -0.441924\n",
      "basinhopping step 22: f -0.440827 trial_f -0.440827 accepted 1  lowest_f -0.441924\n",
      "basinhopping step 23: f -0.441203 trial_f -0.441203 accepted 1  lowest_f -0.441924\n",
      "basinhopping step 24: f -0.44195 trial_f -0.44195 accepted 1  lowest_f -0.44195\n",
      "found new global minimum on step 24 with function value -0.44195\n",
      "basinhopping step 25: f -0.443168 trial_f -0.443168 accepted 1  lowest_f -0.443168\n",
      "found new global minimum on step 25 with function value -0.443168\n",
      "basinhopping step 26: f -0.441772 trial_f -0.441772 accepted 1  lowest_f -0.443168\n",
      "basinhopping step 27: f -0.443812 trial_f -0.443812 accepted 1  lowest_f -0.443812\n",
      "found new global minimum on step 27 with function value -0.443812\n",
      "basinhopping step 28: f -0.442752 trial_f -0.442752 accepted 1  lowest_f -0.443812\n",
      "basinhopping step 29: f -0.444489 trial_f -0.444489 accepted 1  lowest_f -0.444489\n",
      "found new global minimum on step 29 with function value -0.444489\n",
      "basinhopping step 30: f -0.44488 trial_f -0.44488 accepted 1  lowest_f -0.44488\n",
      "found new global minimum on step 30 with function value -0.44488\n",
      "basinhopping step 31: f -0.445393 trial_f -0.445393 accepted 1  lowest_f -0.445393\n",
      "found new global minimum on step 31 with function value -0.445393\n",
      "basinhopping step 32: f -0.445166 trial_f -0.445166 accepted 1  lowest_f -0.445393\n",
      "basinhopping step 33: f -0.444373 trial_f -0.444373 accepted 1  lowest_f -0.445393\n",
      "basinhopping step 34: f -0.444692 trial_f -0.444692 accepted 1  lowest_f -0.445393\n",
      "basinhopping step 35: f -0.44545 trial_f -0.44545 accepted 1  lowest_f -0.44545\n",
      "found new global minimum on step 35 with function value -0.44545\n",
      "basinhopping step 36: f -0.443392 trial_f -0.443392 accepted 1  lowest_f -0.44545\n",
      "basinhopping step 37: f -0.444924 trial_f -0.444924 accepted 1  lowest_f -0.44545\n",
      "basinhopping step 38: f -0.444405 trial_f -0.444405 accepted 1  lowest_f -0.44545\n",
      "basinhopping step 39: f -0.444713 trial_f -0.444713 accepted 1  lowest_f -0.44545\n",
      "basinhopping step 40: f -0.444939 trial_f -0.444939 accepted 1  lowest_f -0.44545\n",
      "basinhopping step 41: f -0.44511 trial_f -0.44511 accepted 1  lowest_f -0.44545\n",
      "basinhopping step 42: f -0.44471 trial_f -0.44471 accepted 1  lowest_f -0.44545\n",
      "basinhopping step 43: f -0.444404 trial_f -0.444404 accepted 1  lowest_f -0.44545\n",
      "basinhopping step 44: f -0.445367 trial_f -0.445367 accepted 1  lowest_f -0.44545\n",
      "basinhopping step 45: f -0.443242 trial_f -0.443242 accepted 1  lowest_f -0.44545\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-66ddfd1261b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_xgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcoe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_coef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_xgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_coe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-c9cd7baf04dd>\u001b[0m in \u001b[0;36msearch_coef\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     55\u001b[0m                                               \u001b[0mstepsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimizer_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"method\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                                               \u001b[0mtake_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                                               interval=100, disp=True, niter_success=20, seed=None)\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_basinhopping.py\u001b[0m in \u001b[0;36mbasinhopping\u001b[0;34m(func, x0, niter, T, stepsize, minimizer_kwargs, take_step, accept_test, callback, interval, disp, niter_success, seed)\u001b[0m\n\u001b[1;32m    674\u001b[0m                \" successfully\"]\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0mnew_global_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_basinhopping.py\u001b[0m in \u001b[0;36mone_cycle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mnew_global_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0maccept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_monte_carlo_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maccept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_basinhopping.py\u001b[0m in \u001b[0;36m_monte_carlo_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# do a local minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mminres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_after_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mx_after_quench\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0menergy_after_quench\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_basinhopping.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x0)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    587\u001b[0m                       callback=callback, **options)\n\u001b[1;32m    588\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'powell'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, **unknown_options)\u001b[0m\n\u001b[1;32m    615\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mone2np1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                         \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                         \u001b[0mfsim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-c9cd7baf04dd>\u001b[0m in \u001b[0;36m_kappa_loss\u001b[0;34m(y, y_true, coef)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0my_fix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_fix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-58e377756040>\u001b[0m in \u001b[0;36mmetric\u001b[0;34m(y1, y2)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# (Quadratic Weigthed Kappa aka Quadratic Cohen Kappa Score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcohen_kappa_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'quadratic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mcohen_kappa_score\u001b[0;34m(y1, y2, labels, weights, sample_weight)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \"\"\"\n\u001b[1;32m    353\u001b[0m     confusion = confusion_matrix(y1, y2, labels=labels,\n\u001b[0;32m--> 354\u001b[0;31m                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0msum0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mlabel_to_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;31m# convert yt, yp into index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mlabel_to_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;31m# convert yt, yp into index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_xgb = split_score(model_xgb, x_train, y_train)\n",
    "\n",
    "coe = search_coef(y_xgb, y_train)\n",
    "\n",
    "best_coe = coe['x']\n",
    "print('最佳参数为',best_coe)\n",
    "\n",
    "yy_xgb = fix_y(y_xgb, best_coe)\n",
    "print('xgb二次加权Kappa系数为:', metric(yy_xgb, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 真实 2.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10折后的Kappa加权得分为:带补充\n",
      "10折后的Kappa加权得分为:带补充\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f5a9a6b1d894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_rf\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msplit_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_xgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_lgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_lgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_lgb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_xgb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_rf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-c9cd7baf04dd>\u001b[0m in \u001b[0;36msplit_score\u001b[0;34m(model, x, y, n)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1337\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my_pre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    640\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m                                        callbacks=callbacks)\n\u001b[0m\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    500\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    211\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1753\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1754\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1755\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1756\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_rf  = split_score(model_rf, x_train, y_train)\n",
    "y_xgb = split_score(model_xgb, x_train, y_train)\n",
    "y_lgb = split_score(model_lgb, x_train, y_train)\n",
    "\n",
    "y = (y_lgb + y_xgb + y_rf)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb分布 Counter({2.0: 4872, 3.0: 3866, 4.0: 3459, 1.0: 2604, 0.0: 187})\n",
      "lgb分布 Counter({2.0: 4727, 4.0: 3680, 3.0: 3354, 1.0: 3127, 0.0: 100})\n",
      "rf分布 Counter({2.0: 5439, 3.0: 3869, 4.0: 3349, 1.0: 2120, 0.0: 211})\n",
      "融合后y分布 Counter({3.0: 4399, 2.0: 4174, 4.0: 3060, 1.0: 2911, 0.0: 449})\n",
      "真实分布 Counter({4: 4195, 2: 4036, 3: 3257, 1: 3090, 0: 410})\n"
     ]
    }
   ],
   "source": [
    "print('xgb分布',(Counter(yy_xgb)))\n",
    "print('lgb分布',(Counter(yy_lgb)))\n",
    "print('rf分布',(Counter(yy_rf)))\n",
    "print('融合后y分布',(Counter(yy)))\n",
    "print('真实分布',(Counter(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basinhopping step 0: f -0.425257\n",
      "basinhopping step 1: f -0.425249 trial_f -0.425249 accepted 1  lowest_f -0.425257\n",
      "basinhopping step 2: f -0.424822 trial_f -0.424822 accepted 1  lowest_f -0.425257\n",
      "basinhopping step 3: f -0.424511 trial_f -0.424511 accepted 1  lowest_f -0.425257\n",
      "basinhopping step 4: f -0.425249 trial_f -0.425249 accepted 1  lowest_f -0.425257\n",
      "basinhopping step 5: f -0.459372 trial_f -0.459372 accepted 1  lowest_f -0.459372\n",
      "found new global minimum on step 5 with function value -0.459372\n",
      "basinhopping step 6: f -0.459356 trial_f -0.459356 accepted 1  lowest_f -0.459372\n",
      "basinhopping step 7: f -0.458796 trial_f -0.458796 accepted 1  lowest_f -0.459372\n",
      "basinhopping step 8: f -0.459541 trial_f -0.459541 accepted 1  lowest_f -0.459541\n",
      "found new global minimum on step 8 with function value -0.459541\n",
      "basinhopping step 9: f -0.458982 trial_f -0.458982 accepted 1  lowest_f -0.459541\n",
      "basinhopping step 10: f -0.460106 trial_f -0.460106 accepted 1  lowest_f -0.460106\n",
      "found new global minimum on step 10 with function value -0.460106\n",
      "basinhopping step 11: f -0.459667 trial_f -0.459667 accepted 1  lowest_f -0.460106\n",
      "basinhopping step 12: f -0.460467 trial_f -0.460467 accepted 1  lowest_f -0.460467\n",
      "found new global minimum on step 12 with function value -0.460467\n",
      "basinhopping step 13: f -0.459722 trial_f -0.459722 accepted 1  lowest_f -0.460467\n",
      "basinhopping step 14: f -0.458418 trial_f -0.458418 accepted 1  lowest_f -0.460467\n",
      "basinhopping step 15: f -0.458675 trial_f -0.458675 accepted 1  lowest_f -0.460467\n",
      "basinhopping step 16: f -0.459095 trial_f -0.459095 accepted 1  lowest_f -0.460467\n",
      "basinhopping step 17: f -0.459016 trial_f -0.459016 accepted 1  lowest_f -0.460467\n",
      "basinhopping step 18: f -0.459225 trial_f -0.459225 accepted 1  lowest_f -0.460467\n",
      "basinhopping step 19: f -0.4592 trial_f -0.4592 accepted 1  lowest_f -0.460467\n",
      "basinhopping step 20: f -0.460784 trial_f -0.460784 accepted 1  lowest_f -0.460784\n",
      "found new global minimum on step 20 with function value -0.460784\n",
      "basinhopping step 21: f -0.460909 trial_f -0.460909 accepted 1  lowest_f -0.460909\n",
      "found new global minimum on step 21 with function value -0.460909\n",
      "basinhopping step 22: f -0.461991 trial_f -0.461991 accepted 1  lowest_f -0.461991\n",
      "found new global minimum on step 22 with function value -0.461991\n",
      "basinhopping step 23: f -0.461802 trial_f -0.461802 accepted 1  lowest_f -0.461991\n",
      "basinhopping step 24: f -0.461658 trial_f -0.461658 accepted 1  lowest_f -0.461991\n",
      "basinhopping step 25: f -0.461607 trial_f -0.461607 accepted 1  lowest_f -0.461991\n",
      "basinhopping step 26: f -0.46306 trial_f -0.46306 accepted 1  lowest_f -0.46306\n",
      "found new global minimum on step 26 with function value -0.46306\n",
      "basinhopping step 27: f -0.463243 trial_f -0.463243 accepted 1  lowest_f -0.463243\n",
      "found new global minimum on step 27 with function value -0.463243\n",
      "basinhopping step 28: f -0.463158 trial_f -0.463158 accepted 1  lowest_f -0.463243\n",
      "basinhopping step 29: f -0.462585 trial_f -0.462585 accepted 1  lowest_f -0.463243\n",
      "basinhopping step 30: f -0.463387 trial_f -0.463387 accepted 1  lowest_f -0.463387\n",
      "found new global minimum on step 30 with function value -0.463387\n",
      "basinhopping step 31: f -0.463615 trial_f -0.463615 accepted 1  lowest_f -0.463615\n",
      "found new global minimum on step 31 with function value -0.463615\n",
      "basinhopping step 32: f -0.462911 trial_f -0.462911 accepted 1  lowest_f -0.463615\n",
      "basinhopping step 33: f -0.463686 trial_f -0.463686 accepted 1  lowest_f -0.463686\n",
      "found new global minimum on step 33 with function value -0.463686\n",
      "basinhopping step 34: f -0.462791 trial_f -0.462791 accepted 1  lowest_f -0.463686\n",
      "basinhopping step 35: f -0.464114 trial_f -0.464114 accepted 1  lowest_f -0.464114\n",
      "found new global minimum on step 35 with function value -0.464114\n",
      "basinhopping step 36: f -0.463306 trial_f -0.463306 accepted 1  lowest_f -0.464114\n",
      "basinhopping step 37: f -0.463654 trial_f -0.463654 accepted 1  lowest_f -0.464114\n",
      "basinhopping step 38: f -0.463628 trial_f -0.463628 accepted 1  lowest_f -0.464114\n",
      "basinhopping step 39: f -0.464297 trial_f -0.464297 accepted 1  lowest_f -0.464297\n",
      "found new global minimum on step 39 with function value -0.464297\n",
      "basinhopping step 40: f -0.464007 trial_f -0.464007 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 41: f -0.463277 trial_f -0.463277 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 42: f -0.462841 trial_f -0.462841 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 43: f -0.462789 trial_f -0.462789 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 44: f -0.462766 trial_f -0.462766 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 45: f -0.463244 trial_f -0.463244 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 46: f -0.464027 trial_f -0.464027 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 47: f -0.462533 trial_f -0.462533 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 48: f -0.4631 trial_f -0.4631 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 49: f -0.462846 trial_f -0.462846 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 50: f -0.462961 trial_f -0.462961 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 51: f -0.46382 trial_f -0.46382 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 52: f -0.463359 trial_f -0.463359 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 53: f -0.462753 trial_f -0.462753 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 54: f -0.464147 trial_f -0.464147 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 55: f -0.463689 trial_f -0.463689 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 56: f -0.463371 trial_f -0.463371 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 57: f -0.462589 trial_f -0.462589 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 58: f -0.463208 trial_f -0.463208 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 59: f -0.462389 trial_f -0.462389 accepted 1  lowest_f -0.464297\n",
      "basinhopping step 60: f -0.46328 trial_f -0.46328 accepted 1  lowest_f -0.464297\n",
      "[1.74002941 2.10839196 2.46356091 2.88981677]\n",
      "融合后的分布: Counter({2.0: 4015, 3.0: 3877, 4.0: 3536, 1.0: 2874, 0.0: 686})\n",
      "融合后的二次加权Kappa系数为 0.46429667658520946\n",
      "y的真实分布为 Counter({4: 4195, 2: 4036, 3: 3257, 1: 3090, 0: 410})\n"
     ]
    }
   ],
   "source": [
    "y = (y_lgb + y_xgb + y_rf)/3\n",
    "\n",
    "sort_y = y.argsort()[:int(0.030*len(y_rf))]\n",
    "y[sort_y] = y[sort_y] - 0.2\n",
    "\n",
    "coe = search_coef(y, y_train)\n",
    "\n",
    "best_coe = coe['x']\n",
    "print(best_coe)  \n",
    "\n",
    "yy = fix_y(y, best_coe)\n",
    "print('融合后的分布:',Counter(yy))\n",
    "print('融合后的二次加权Kappa系数为', metric(yy, y_train))\n",
    "print('y的真实分布为',Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RescuerID_count</th>\n",
       "      <td>2495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD_Description_0</th>\n",
       "      <td>2035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD_Description_1</th>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhotoAmt</th>\n",
       "      <td>1835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD_Description_4</th>\n",
       "      <td>1778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD_token_0</th>\n",
       "      <td>1732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD_Description_3</th>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD_token_4</th>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breed1</th>\n",
       "      <td>1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD_token_1</th>\n",
       "      <td>1536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD_Description_2</th>\n",
       "      <td>1513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD_token_2</th>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_Description_0</th>\n",
       "      <td>1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD_token_3</th>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_Description_4</th>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_breed_BreedName</th>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_Description_3</th>\n",
       "      <td>1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_token_4</th>\n",
       "      <td>1222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_token_1</th>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_Description_1</th>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_token_3</th>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_Description_2</th>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_score</th>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_token_2</th>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_magnitude</th>\n",
       "      <td>976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_breed_BreedName</th>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fee</th>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_score</th>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color1</th>\n",
       "      <td>774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breed2</th>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_magnitude</th>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank.sentence_score</th>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color2</th>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantity</th>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_token_0</th>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sterilized</th>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FurLength</th>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaturitySize</th>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank.sentence_magnitude</th>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vaccinated</th>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dewormed</th>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank.document_score</th>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_qcut</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color3</th>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank.document_magnitude</th>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>middle</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoAmt</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charities</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasSecondBreed</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsFree</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_breed_Type</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_breed_Type</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "RescuerID_count          2495\n",
       "SVD_Description_0        2035\n",
       "SVD_Description_1        1861\n",
       "PhotoAmt                 1835\n",
       "SVD_Description_4        1778\n",
       "Age                      1746\n",
       "SVD_token_0              1732\n",
       "SVD_Description_3        1727\n",
       "SVD_token_4              1600\n",
       "Breed1                   1576\n",
       "SVD_token_1              1536\n",
       "SVD_Description_2        1513\n",
       "SVD_token_2              1462\n",
       "NMF_Description_0        1449\n",
       "SVD_token_3              1422\n",
       "NMF_Description_4        1369\n",
       "main_breed_BreedName     1357\n",
       "NMF_Description_3        1293\n",
       "NMF_token_4              1222\n",
       "NMF_token_1              1193\n",
       "NMF_Description_1        1155\n",
       "State                    1127\n",
       "NMF_token_3              1066\n",
       "NMF_Description_2        1048\n",
       "document_score           1020\n",
       "NMF_token_2               994\n",
       "sentence_magnitude        976\n",
       "second_breed_BreedName    826\n",
       "Fee                       785\n",
       "sentence_score            778\n",
       "Color1                    774\n",
       "Breed2                    759\n",
       "document_magnitude        739\n",
       "rank.sentence_score       719\n",
       "Color2                    690\n",
       "Quantity                  647\n",
       "NMF_token_0               599\n",
       "Sterilized                557\n",
       "FurLength                 528\n",
       "MaturitySize              507\n",
       "rank.sentence_magnitude   464\n",
       "Vaccinated                388\n",
       "Dewormed                  348\n",
       "rank.document_score       321\n",
       "Gender                    293\n",
       "Age_qcut                  278\n",
       "Color3                    274\n",
       "rank.document_magnitude   204\n",
       "Year                      189\n",
       "middle                    177\n",
       "VideoAmt                  177\n",
       "Health                    174\n",
       "single                    155\n",
       "Charities                  97\n",
       "Type                       97\n",
       "HasSecondBreed             62\n",
       "IsFree                     46\n",
       "main_breed_Type            40\n",
       "second_breed_Type          40"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb.feature_importances_\n",
    "a = pd.DataFrame(model_lgb.feature_importances_, index=x_train.columns)\n",
    "a.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(2.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307    0.381284\n",
       "266    0.631707\n",
       "265    0.716677\n",
       "299    0.742871\n",
       "264    0.763836\n",
       "292    0.780999\n",
       "285    0.795469\n",
       "205    0.808988\n",
       "141    0.821610\n",
       "179    0.832700\n",
       "109    0.843103\n",
       "218    0.853295\n",
       "254    0.861322\n",
       "189    0.867976\n",
       "103    0.874525\n",
       "213    0.880756\n",
       "243    0.886724\n",
       "20     0.892533\n",
       "283    0.897497\n",
       "247    0.902302\n",
       "152    0.906686\n",
       "195    0.911016\n",
       "128    0.915294\n",
       "78     0.919149\n",
       "306    0.922951\n",
       "303    0.926120\n",
       "69     0.929077\n",
       "76     0.931612\n",
       "60     0.934147\n",
       "276    0.936576\n",
       "         ...   \n",
       "99     0.998469\n",
       "146    0.998521\n",
       "3      0.998574\n",
       "6      0.998627\n",
       "290    0.998680\n",
       "258    0.998733\n",
       "278    0.998785\n",
       "130    0.998838\n",
       "23     0.998891\n",
       "257    0.998944\n",
       "222    0.998997\n",
       "104    0.999049\n",
       "2      0.999102\n",
       "116    0.999155\n",
       "14     0.999208\n",
       "93     0.999261\n",
       "142    0.999313\n",
       "81     0.999366\n",
       "64     0.999419\n",
       "112    0.999472\n",
       "125    0.999525\n",
       "192    0.999578\n",
       "94     0.999630\n",
       "61     0.999683\n",
       "126    0.999736\n",
       "298    0.999789\n",
       "123    0.999842\n",
       "217    0.999894\n",
       "139    0.999947\n",
       "16     1.000000\n",
       "Name: Breed1, Length: 188, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_train.append(x_test)\n",
    "a = x['Breed1'].value_counts().sort_values(ascending = False).cumsum()/len(x)\n",
    "rare_index = a[a > 0.9].index.tolist()\n",
    "rare_index\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
