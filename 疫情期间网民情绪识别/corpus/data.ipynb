{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T03:49:25.620019Z",
     "start_time": "2020-04-17T03:49:25.609896Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练数据预处理\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, AdamW, BertModel, BertPreTrainedModel, BertConfig, AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T10:30:03.441045Z",
     "start_time": "2020-04-15T10:30:03.329275Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 10:30:03.341242 140138955777792 configuration_utils.py:281] loading configuration file /home/zhoujx/Pretrained_models/chinese_roberta_wwm_large_ext_pytorch/bert_config.json\n",
      "I0415 10:30:03.344393 140138955777792 configuration_utils.py:319] Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0415 10:30:03.346396 140138955777792 tokenization_utils.py:420] Model name '/home/zhoujx/Pretrained_models/chinese_roberta_wwm_large_ext_pytorch/vocab.txt' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '/home/zhoujx/Pretrained_models/chinese_roberta_wwm_large_ext_pytorch/vocab.txt' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "W0415 10:30:03.347954 140138955777792 tokenization_utils.py:432] Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n",
      "I0415 10:30:03.349654 140138955777792 tokenization_utils.py:502] loading file /home/zhoujx/Pretrained_models/chinese_roberta_wwm_large_ext_pytorch/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# tokenizer  = AutoTokenizer.from_pretrained('/home/zhoujx/Pretrained_models/chinese_xlnet_base_pytorch')\n",
    "bert_config = BertConfig.from_pretrained(r'/home/zhoujx/Pretrained_models/chinese_roberta_wwm_large_ext_pytorch/bert_config.json', output_hidden_states=True)\n",
    "tokenizer  = BertTokenizer.from_pretrained(r'/home/zhoujx/Pretrained_models/chinese_roberta_wwm_large_ext_pytorch/vocab.txt', config=bert_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T03:50:02.981103Z",
     "start_time": "2020-04-17T03:50:01.505828Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"./nCoV_100k_train.labled.csv\")\n",
    "df_test = pd.read_csv(r\"./nCov_10k_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T03:50:09.038143Z",
     "start_time": "2020-04-17T03:50:09.010452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>微博id</th>\n",
       "      <th>微博发布时间</th>\n",
       "      <th>发布人账号</th>\n",
       "      <th>微博中文内容</th>\n",
       "      <th>微博图片</th>\n",
       "      <th>微博视频</th>\n",
       "      <th>情感倾向</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4456072029125500</td>\n",
       "      <td>01月01日 23:50</td>\n",
       "      <td>存曦1988</td>\n",
       "      <td>写在年末冬初孩子流感的第五天，我们仍然没有忘记热情拥抱这2020年的第一天。带着一丝迷信，早...</td>\n",
       "      <td>['https://ww2.sinaimg.cn/orj360/005VnA1zly1gah...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4456074167480980</td>\n",
       "      <td>01月01日 23:58</td>\n",
       "      <td>LunaKrys</td>\n",
       "      <td>开年大模型…累到以为自己发烧了腰疼膝盖疼腿疼胳膊疼脖子疼#Luna的Krystallife#?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4456054253264520</td>\n",
       "      <td>01月01日 22:39</td>\n",
       "      <td>小王爷学辩论o_O</td>\n",
       "      <td>邱晨这就是我爹，爹，发烧快好，毕竟美好的假期拿来养病不太好，假期还是要好好享受快乐，爹，新...</td>\n",
       "      <td>['https://ww2.sinaimg.cn/thumb150/006ymYXKgy1g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4456061509126470</td>\n",
       "      <td>01月01日 23:08</td>\n",
       "      <td>芩鎟</td>\n",
       "      <td>新年的第一天感冒又发烧的也太衰了但是我要想着明天一定会好的?</td>\n",
       "      <td>['https://ww2.sinaimg.cn/orj360/005FL9LZgy1gah...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4455979322528190</td>\n",
       "      <td>01月01日 17:42</td>\n",
       "      <td>changlwj</td>\n",
       "      <td>问：我们意念里有坏的想法了，天神就会给记下来，那如果有好的想法也会被记下来吗？答：那当然了。...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               微博id        微博发布时间      发布人账号  \\\n",
       "0  4456072029125500  01月01日 23:50     存曦1988   \n",
       "1  4456074167480980  01月01日 23:58   LunaKrys   \n",
       "2  4456054253264520  01月01日 22:39  小王爷学辩论o_O   \n",
       "3  4456061509126470  01月01日 23:08         芩鎟   \n",
       "4  4455979322528190  01月01日 17:42   changlwj   \n",
       "\n",
       "                                              微博中文内容  \\\n",
       "0  写在年末冬初孩子流感的第五天，我们仍然没有忘记热情拥抱这2020年的第一天。带着一丝迷信，早...   \n",
       "1    开年大模型…累到以为自己发烧了腰疼膝盖疼腿疼胳膊疼脖子疼#Luna的Krystallife#?   \n",
       "2  邱晨这就是我爹，爹，发烧快好，毕竟美好的假期拿来养病不太好，假期还是要好好享受快乐，爹，新...   \n",
       "3                     新年的第一天感冒又发烧的也太衰了但是我要想着明天一定会好的?   \n",
       "4  问：我们意念里有坏的想法了，天神就会给记下来，那如果有好的想法也会被记下来吗？答：那当然了。...   \n",
       "\n",
       "                                                微博图片 微博视频 情感倾向  \n",
       "0  ['https://ww2.sinaimg.cn/orj360/005VnA1zly1gah...   []    0  \n",
       "1                                                 []   []   -1  \n",
       "2  ['https://ww2.sinaimg.cn/thumb150/006ymYXKgy1g...   []    1  \n",
       "3  ['https://ww2.sinaimg.cn/orj360/005FL9LZgy1gah...   []    1  \n",
       "4                                                 []   []    1  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_data & dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T03:49:27.944032Z",
     "start_time": "2020-04-17T03:49:27.857399Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['微博中文内容'] = df_train.微博中文内容.fillna('内容缺失')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T03:49:30.753642Z",
     "start_time": "2020-04-17T03:49:30.738595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['微博id', '微博发布时间', '发布人账号', '微博中文内容', '微博图片', '微博视频', '情感倾向'], dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T06:19:08.002807Z",
     "start_time": "2020-04-15T06:19:07.987736Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(df):\n",
    "    with tqdm.tqdm(range(df.shape[0])) as qbar:\n",
    "        input_ids_list = []\n",
    "        token_type_ids_list = []\n",
    "        attention_mask_list = []\n",
    "        for idx in qbar:\n",
    "            tokenize_out = tokenizer.encode_plus(df.loc[idx, '微博中文内容'], pad_to_max_length=True, max_length=150)\n",
    "            input_ids = tokenize_out['input_ids']\n",
    "            token_type_ids = tokenize_out['token_type_ids']\n",
    "            attention_mask = tokenize_out['attention_mask']\n",
    "\n",
    "            input_ids_list.append(input_ids)\n",
    "            token_type_ids_list.append(token_type_ids)\n",
    "            attention_mask_list.append(attention_mask)\n",
    "    \n",
    "    df['input_ids'] = input_ids_list\n",
    "    df['token_type_ids'] = token_type_ids_list\n",
    "    df['attention_mask'] = attention_mask_list\n",
    "    df.drop(['微博发布时间','发布人账号','微博中文内容','微博图片','微博视频'], axis=1, inplace=True)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T06:23:18.973241Z",
     "start_time": "2020-04-15T06:19:08.006933Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [04:07<00:00, 307.27it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train = get_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T06:23:35.444758Z",
     "start_time": "2020-04-15T06:23:18.996290Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.情感倾向.isin(['-1','0','1',-1,0,1])]\n",
    "# df_train['情感倾向'] = df_train.情感倾向.astype(str)\n",
    "df_train['情感倾向'] = df_train.情感倾向.map({'-1':0, '0':1, '1':2})\n",
    "df_train = df_train.reset_index()\n",
    "df_train.to_csv('./df_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T10:30:21.824235Z",
     "start_time": "2020-04-15T10:30:21.807938Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['微博中文内容'] = df_test.微博中文内容.fillna('内容缺失')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T10:30:29.185236Z",
     "start_time": "2020-04-15T10:30:29.175748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['微博id', '微博发布时间', '发布人账号', '微博中文内容', '微博图片', '微博视频'], dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T10:30:31.774760Z",
     "start_time": "2020-04-15T10:30:31.759864Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_data(df):\n",
    "    with tqdm.tqdm(range(df.shape[0])) as qbar:\n",
    "        input_ids_list = []\n",
    "        token_type_ids_list = []\n",
    "        attention_mask_list = []\n",
    "        for idx in qbar:\n",
    "            tokenize_out = tokenizer.encode_plus(df.loc[idx, '微博中文内容'], pad_to_max_length=True, max_length=150)\n",
    "            input_ids = tokenize_out['input_ids']\n",
    "            token_type_ids = tokenize_out['token_type_ids']\n",
    "            attention_mask = tokenize_out['attention_mask']\n",
    "\n",
    "            input_ids_list.append(input_ids)\n",
    "            token_type_ids_list.append(token_type_ids)\n",
    "            attention_mask_list.append(attention_mask)\n",
    "    \n",
    "    df['input_ids'] = input_ids_list\n",
    "    df['token_type_ids'] = token_type_ids_list\n",
    "    df['attention_mask'] = attention_mask_list\n",
    "    df.drop(['微博发布时间','发布人账号','微博中文内容','微博图片','微博视频'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T10:31:09.724300Z",
     "start_time": "2020-04-15T10:30:45.312234Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:24<00:00, 416.17it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test = get_test_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T10:31:15.794739Z",
     "start_time": "2020-04-15T10:31:14.342806Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = df_test.reset_index()\n",
    "df_test.to_csv('./df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T10:31:23.551982Z",
     "start_time": "2020-04-15T10:31:23.477891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>微博id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4456068992182160</td>\n",
       "      <td>[101, 108, 872, 1962, 8439, 108, 3173, 2399, 5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4456424178427250</td>\n",
       "      <td>[101, 1920, 2140, 1348, 2697, 1088, 7965, 1853...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4456797466940200</td>\n",
       "      <td>[101, 6820, 6206, 1343, 6783, 697, 1921, 3890,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4456791021108920</td>\n",
       "      <td>[101, 2769, 1922, 7410, 749, 1166, 782, 2582, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4457086404997440</td>\n",
       "      <td>[101, 3362, 4197, 3221, 6206, 4567, 671, 1767,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              微博id                                          input_ids  \\\n",
       "0      0  4456068992182160  [101, 108, 872, 1962, 8439, 108, 3173, 2399, 5...   \n",
       "1      1  4456424178427250  [101, 1920, 2140, 1348, 2697, 1088, 7965, 1853...   \n",
       "2      2  4456797466940200  [101, 6820, 6206, 1343, 6783, 697, 1921, 3890,...   \n",
       "3      3  4456791021108920  [101, 2769, 1922, 7410, 749, 1166, 782, 2582, ...   \n",
       "4      4  4457086404997440  [101, 3362, 4197, 3221, 6206, 4567, 671, 1767,...   \n",
       "\n",
       "                                      token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
