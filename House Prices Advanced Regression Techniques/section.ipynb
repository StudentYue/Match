{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# The error metric: RMSE on the log of the sale prices.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import skew\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "################################################################################\n",
    "class CustomEnsembleRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, regressors=None):\n",
    "        self.regressors = regressors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for regressor in self.regressors:\n",
    "            regressor.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.predictions_ = list()\n",
    "        for regressor in self.regressors:\n",
    "            self.predictions_.append(np.exp(regressor.predict(X).ravel()))\n",
    "\n",
    "        return np.log1p(np.mean(self.predictions_, axis=0))\n",
    "        \n",
    "################################################################################\n",
    "# RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def factorize(df, factor_df, column, fill_na=None):\n",
    "    factor_df[column] = df[column]\n",
    "    if fill_na is not None:\n",
    "        factor_df[column].fillna(fill_na, inplace=True)\n",
    "    le.fit(factor_df[column].unique())\n",
    "    factor_df[column] = le.transform(factor_df[column])\n",
    "    return factor_df\n",
    "\n",
    "# Combine all the (numerical) features into one big DataFrame. We don't add \n",
    "# the one-hot encoded variables here yet, that happens later on.\n",
    "def munge(df):\n",
    "    all_df = pd.DataFrame(index = df.index)\n",
    "   \n",
    "    all_df['LotFrontage'] = df['LotFrontage']   \n",
    "    for key, group in lot_frontage_by_neighborhood:\n",
    "        idx = (df['Neighborhood'] == key) & (df['LotFrontage'].isnull())\n",
    "        all_df.loc[idx, 'LotFrontage'] = group.median()    \n",
    "\n",
    "    all_df['LotArea'] = df['LotArea']\n",
    "\n",
    "    all_df['MasVnrArea'] = df['MasVnrArea']\n",
    "    all_df['MasVnrArea'].fillna(0, inplace=True)\n",
    "   \n",
    "    all_df['BsmtFinSF1'] = df['BsmtFinSF1']\n",
    "    all_df['BsmtFinSF1'].fillna(0, inplace=True)\n",
    "\n",
    "    all_df['BsmtFinSF2'] = df['BsmtFinSF2']\n",
    "    all_df['BsmtFinSF2'].fillna(0, inplace=True)\n",
    "\n",
    "    all_df['BsmtUnfSF'] = df['BsmtUnfSF']\n",
    "    all_df['BsmtUnfSF'].fillna(0, inplace=True)\n",
    "\n",
    "    all_df['TotalBsmtSF'] = df['TotalBsmtSF']\n",
    "    all_df['TotalBsmtSF'].fillna(0, inplace=True)\n",
    "\n",
    "    all_df['1stFlrSF'] = df['1stFlrSF']\n",
    "    all_df['2ndFlrSF'] = df['2ndFlrSF']\n",
    "    all_df['GrLivArea'] = df['GrLivArea']\n",
    "    \n",
    "    all_df['GarageArea'] = df['GarageArea']\n",
    "    all_df['GarageArea'].fillna(0, inplace=True)\n",
    "\n",
    "    all_df['WoodDeckSF'] = df['WoodDeckSF']\n",
    "    all_df['OpenPorchSF'] = df['OpenPorchSF']\n",
    "    all_df['EnclosedPorch'] = df['EnclosedPorch']\n",
    "    all_df['3SsnPorch'] = df['3SsnPorch']\n",
    "    all_df['ScreenPorch'] = df['ScreenPorch']\n",
    "    \n",
    "    all_df['BsmtFullBath'] = df['BsmtFullBath']\n",
    "    all_df['BsmtFullBath'].fillna(0, inplace=True)\n",
    "\n",
    "    all_df['BsmtHalfBath'] = df['BsmtHalfBath']\n",
    "    all_df['BsmtHalfBath'].fillna(0, inplace=True)\n",
    "\n",
    "    all_df['FullBath'] = df['FullBath'] \n",
    "    all_df['HalfBath'] = df['HalfBath'] \n",
    "    all_df['BedroomAbvGr'] = df['BedroomAbvGr'] \n",
    "    all_df['KitchenAbvGr'] = df['KitchenAbvGr'] \n",
    "    all_df['TotRmsAbvGrd'] = df['TotRmsAbvGrd'] \n",
    "    all_df['Fireplaces'] = df['Fireplaces'] \n",
    "\n",
    "    all_df['GarageCars'] = df['GarageCars']\n",
    "    all_df['GarageCars'].fillna(0, inplace=True)\n",
    "\n",
    "    all_df['CentralAir'] = (df['CentralAir'] == 'Y') * 1.0\n",
    "   \n",
    "    all_df['OverallQual'] = df['OverallQual']\n",
    "    all_df['OverallCond'] = df['OverallCond']\n",
    "\n",
    "    # Quality measurements are stored as text but we can convert them to \n",
    "    # numbers where a higher number means higher quality.\n",
    "\n",
    "    qual_dict = {None: 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "    all_df['ExterQual'] = df['ExterQual'].map(qual_dict).astype(int)\n",
    "    all_df['ExterCond'] = df['ExterCond'].map(qual_dict).astype(int)\n",
    "    all_df['BsmtQual'] = df['BsmtQual'].map(qual_dict).astype(int)\n",
    "    all_df['BsmtCond'] = df['BsmtCond'].map(qual_dict).astype(int)\n",
    "    all_df['HeatingQC'] = df['HeatingQC'].map(qual_dict).astype(int)\n",
    "    all_df['KitchenQual'] = df['KitchenQual'].map(qual_dict).astype(int)\n",
    "    all_df['FireplaceQu'] = df['FireplaceQu'].map(qual_dict).astype(int)\n",
    "    all_df['GarageQual'] = df['GarageQual'].map(qual_dict).astype(int)\n",
    "    all_df['GarageCond'] = df['GarageCond'].map(qual_dict).astype(int)\n",
    "\n",
    "    all_df['BsmtExposure'] = df['BsmtExposure'].map(\n",
    "        {None: 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4}).astype(int)\n",
    "\n",
    "    bsmt_fin_dict = {None: 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n",
    "    all_df['BsmtFinType1'] = df['BsmtFinType1'].map(bsmt_fin_dict).astype(int)\n",
    "    all_df['BsmtFinType2'] = df['BsmtFinType2'].map(bsmt_fin_dict).astype(int)\n",
    "\n",
    "    all_df['Functional'] = df['Functional'].map(\n",
    "        {None: 0, 'Sal': 1, 'Sev': 2, 'Maj2': 3, 'Maj1': 4, \n",
    "         'Mod': 5, 'Min2': 6, 'Min1': 7, 'Typ': 8}).astype(int)\n",
    "\n",
    "    all_df['GarageFinish'] = df['GarageFinish'].map(\n",
    "        {None: 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}).astype(int)\n",
    "\n",
    "    all_df['Fence'] = df['Fence'].map(\n",
    "        {None: 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4}).astype(int)\n",
    "\n",
    "    all_df['YearBuilt'] = df['YearBuilt']\n",
    "    all_df['YearRemodAdd'] = df['YearRemodAdd']\n",
    "\n",
    "    all_df['GarageYrBlt'] = df['GarageYrBlt']\n",
    "    all_df['GarageYrBlt'].fillna(0.0, inplace=True)\n",
    "\n",
    "    all_df['MoSold'] = df['MoSold']\n",
    "    all_df['YrSold'] = df['YrSold']\n",
    "    \n",
    "    all_df['LowQualFinSF'] = df['LowQualFinSF']\n",
    "    all_df['MiscVal'] = df['MiscVal']\n",
    "\n",
    "    all_df['PoolQC'] = df['PoolQC'].map(qual_dict).astype(int)\n",
    "\n",
    "    all_df['PoolArea'] = df['PoolArea']\n",
    "    all_df['PoolArea'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Add categorical features as numbers too. It seems to help a bit.\n",
    "    all_df = factorize(df, all_df, 'MSSubClass')\n",
    "    all_df = factorize(df, all_df, 'MSZoning', 'RL')\n",
    "    all_df = factorize(df, all_df, 'LotConfig')\n",
    "    all_df = factorize(df, all_df, 'Neighborhood')\n",
    "    all_df = factorize(df, all_df, 'Condition1')\n",
    "    all_df = factorize(df, all_df, 'BldgType')\n",
    "    all_df = factorize(df, all_df, 'HouseStyle')\n",
    "    all_df = factorize(df, all_df, 'RoofStyle')\n",
    "    all_df = factorize(df, all_df, 'Exterior1st', 'Other')\n",
    "    all_df = factorize(df, all_df, 'Exterior2nd', 'Other')\n",
    "    all_df = factorize(df, all_df, 'MasVnrType', 'None')\n",
    "    all_df = factorize(df, all_df, 'Foundation')\n",
    "    all_df = factorize(df, all_df, 'SaleType', 'Oth')\n",
    "    all_df = factorize(df, all_df, 'SaleCondition')\n",
    "\n",
    "    # IR2 and IR3 don't appear that often, so just make a distinction\n",
    "    # between regular and irregular.\n",
    "    all_df['IsRegularLotShape'] = (df['LotShape'] == 'Reg') * 1\n",
    "\n",
    "    # Most properties are level; bin the other possibilities together\n",
    "    # as 'not level'.\n",
    "    all_df['IsLandLevel'] = (df['LandContour'] == 'Lvl') * 1\n",
    "\n",
    "    # Most land slopes are gentle; treat the others as 'not gentle'.\n",
    "    all_df['IsLandSlopeGentle'] = (df['LandSlope'] == 'Gtl') * 1\n",
    "\n",
    "    # Most properties use standard circuit breakers.\n",
    "    all_df['IsElectricalSBrkr'] = (df['Electrical'] == 'SBrkr') * 1\n",
    "\n",
    "    # About 2/3rd have an attached garage.\n",
    "    all_df['IsGarageDetached'] = (df['GarageType'] == 'Detchd') * 1\n",
    "\n",
    "    # Most have a paved drive. Treat dirt/gravel and partial pavement\n",
    "    # as 'not paved'.\n",
    "    all_df['IsPavedDrive'] = (df['PavedDrive'] == 'Y') * 1\n",
    "\n",
    "    # The only interesting 'misc. feature' is the presence of a shed.\n",
    "    all_df['HasShed'] = (df['MiscFeature'] == 'Shed') * 1.  \n",
    "\n",
    "    # If YearRemodAdd != YearBuilt, then a remodeling took place at some point.\n",
    "    all_df['Remodeled'] = (all_df['YearRemodAdd'] != all_df['YearBuilt']) * 1\n",
    "    \n",
    "    # Did a remodeling happen in the year the house was sold?\n",
    "    all_df['RecentRemodel'] = (all_df['YearRemodAdd'] == all_df['YrSold']) * 1\n",
    "    \n",
    "    # Was this house sold in the year it was built?\n",
    "    all_df['VeryNewHouse'] = (all_df['YearBuilt'] == all_df['YrSold']) * 1\n",
    "\n",
    "    all_df['Has2ndFloor'] = (all_df['2ndFlrSF'] == 0) * 1\n",
    "    all_df['HasMasVnr'] = (all_df['MasVnrArea'] == 0) * 1\n",
    "    all_df['HasWoodDeck'] = (all_df['WoodDeckSF'] == 0) * 1\n",
    "    all_df['HasOpenPorch'] = (all_df['OpenPorchSF'] == 0) * 1\n",
    "    all_df['HasEnclosedPorch'] = (all_df['EnclosedPorch'] == 0) * 1\n",
    "    all_df['Has3SsnPorch'] = (all_df['3SsnPorch'] == 0) * 1\n",
    "    all_df['HasScreenPorch'] = (all_df['ScreenPorch'] == 0) * 1\n",
    "\n",
    "    # These features actually lower the score a little.\n",
    "    # all_df['HasBasement'] = df['BsmtQual'].isnull() * 1\n",
    "    # all_df['HasGarage'] = df['GarageQual'].isnull() * 1\n",
    "    # all_df['HasFireplace'] = df['FireplaceQu'].isnull() * 1\n",
    "    # all_df['HasFence'] = df['Fence'].isnull() * 1\n",
    "\n",
    "    # Months with the largest number of deals may be significant.\n",
    "    all_df['HighSeason'] = df['MoSold'].replace( \n",
    "        {1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0})\n",
    "\n",
    "    all_df['NewerDwelling'] = df['MSSubClass'].replace(\n",
    "        {20: 1, 30: 0, 40: 0, 45: 0,50: 0, 60: 1, 70: 0, 75: 0, 80: 0, 85: 0,\n",
    "         90: 0, 120: 1, 150: 0, 160: 0, 180: 0, 190: 0})   \n",
    "    \n",
    "    all_df.loc[df.Neighborhood == 'NridgHt', 'Neighborhood_Good'] = 1\n",
    "    all_df.loc[df.Neighborhood == 'Crawfor', 'Neighborhood_Good'] = 1\n",
    "    all_df.loc[df.Neighborhood == 'StoneBr', 'Neighborhood_Good'] = 1\n",
    "    all_df.loc[df.Neighborhood == 'Somerst', 'Neighborhood_Good'] = 1\n",
    "    all_df.loc[df.Neighborhood == 'NoRidge', 'Neighborhood_Good'] = 1\n",
    "    all_df['Neighborhood_Good'].fillna(0, inplace=True)\n",
    "\n",
    "    all_df['SaleCondition_PriceDown'] = df.SaleCondition.replace(\n",
    "        # {'Abnorml': 1, 'Alloca': 1, 'AdjLand': 1, 'Family': 1, 'Normal': 0, 'Partial': 0})\n",
    "        {'Abnorml': 1, 'Alloca': 2, 'AdjLand': 3, 'Family': 4, 'Normal': 5, 'Partial': 0})\n",
    "\n",
    "    # House completed before sale or not\n",
    "    all_df['BoughtOffPlan'] = df.SaleCondition.replace(\n",
    "        {'Abnorml' : 0, 'Alloca' : 0, 'AdjLand' : 0, 'Family' : 0, 'Normal' : 0, 'Partial' : 1})\n",
    "    \n",
    "    # all_df['BadHeating'] = df.HeatingQC.replace(\n",
    "    #     {'Ex': 0, 'Gd': 0, 'TA': 0, 'Fa': 1, 'Po': 1})\n",
    "    all_df['BadHeating'] = df.HeatingQC.replace(\n",
    "        {'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4})\n",
    "\n",
    "    area_cols = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "                 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', \n",
    "                 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'LowQualFinSF', 'PoolArea' ]\n",
    "    all_df['TotalArea'] = all_df[area_cols].sum(axis=1)\n",
    "\n",
    "    all_df['TotalArea1st2nd'] = all_df['1stFlrSF'] + all_df['2ndFlrSF']\n",
    "\n",
    "    all_df['Age'] = 2010 - all_df['YearBuilt']\n",
    "    all_df['TimeSinceSold'] = 2010 - all_df['YrSold']\n",
    "\n",
    "    # If commented - a little bit worse on LB but better in CV\n",
    "    all_df['SeasonSold'] = all_df['MoSold'].map({12:0, 1:0, 2:0, 3:1, 4:1, 5:1, \n",
    "                                                  6:2, 7:2, 8:2, 9:3, 10:3, 11:3}).astype(int)\n",
    "    \n",
    "    all_df['YearsSinceRemodel'] = all_df['YrSold'] - all_df['YearRemodAdd']\n",
    "    \n",
    "    # Simplifications of existing features into bad/average/good.\n",
    "    # all_df['SimplOverallQual'] = all_df.OverallQual.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2, 7 : 3, 8 : 3, 9 : 3, 10 : 3})\n",
    "    # all_df['SimplOverallCond'] = all_df.OverallCond.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2, 7 : 3, 8 : 3, 9 : 3, 10 : 3})\n",
    "    # all_df['SimplPoolQC'] = all_df.PoolQC.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 2, 4 : 2})\n",
    "    # all_df['SimplGarageCond'] = all_df.GarageCond.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    # all_df['SimplGarageQual'] = all_df.GarageQual.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    # all_df['SimplFireplaceQu'] = all_df.FireplaceQu.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    # all_df['SimplFireplaceQu'] = all_df.FireplaceQu.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    # all_df['SimplFunctional'] = all_df.Functional.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 2, 4 : 2, 5 : 3, 6 : 3, 7 : 3, 8 : 4})\n",
    "    # all_df['SimplKitchenQual'] = all_df.KitchenQual.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    # all_df['SimplHeatingQC'] = all_df.HeatingQC.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    # all_df['SimplBsmtFinType1'] = all_df.BsmtFinType1.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2})\n",
    "    # all_df['SimplBsmtFinType2'] = all_df.BsmtFinType2.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2})\n",
    "    # all_df['SimplBsmtCond'] = all_df.BsmtCond.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    # all_df['SimplBsmtQual'] = all_df.BsmtQual.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    # all_df['SimplExterCond'] = all_df.ExterCond.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    # all_df['SimplExterQual'] = all_df.ExterQual.replace(\n",
    "    #     {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "\n",
    "    all_df['SimplOverallQual'] = all_df.OverallQual\n",
    "    all_df['SimplOverallCond'] = all_df.OverallCond\n",
    "    all_df['SimplPoolQC'] = all_df.PoolQC\n",
    "    all_df['SimplGarageCond'] = all_df.GarageCond\n",
    "    all_df['SimplGarageQual'] = all_df.GarageQual\n",
    "    all_df['SimplFireplaceQu'] = all_df.FireplaceQu\n",
    "    all_df['SimplFireplaceQu'] = all_df.FireplaceQu\n",
    "    all_df['SimplFunctional'] = all_df.Functional\n",
    "    all_df['SimplKitchenQual'] = all_df.KitchenQual\n",
    "    all_df['SimplHeatingQC'] = all_df.HeatingQC\n",
    "    all_df['SimplBsmtFinType1'] = all_df.BsmtFinType1\n",
    "    all_df['SimplBsmtFinType2'] = all_df.BsmtFinType2\n",
    "    all_df['SimplBsmtCond'] = all_df.BsmtCond\n",
    "    all_df['SimplBsmtQual'] = all_df.BsmtQual\n",
    "    all_df['SimplExterCond'] = all_df.ExterCond\n",
    "    all_df['SimplExterQual'] = all_df.ExterQual\n",
    "            \n",
    "    # Bin by neighborhood (a little arbitrarily). Values were computed by: \n",
    "    # train_df['SalePrice'].groupby(train_df['Neighborhood']).median().sort_values()\n",
    "    neighborhood_map = {\n",
    "        'MeadowV' : 0,  #  88000\n",
    "        'IDOTRR' : 1,   # 103000\n",
    "        'BrDale' : 1,   # 106000\n",
    "        'OldTown' : 1,  # 119000\n",
    "        'Edwards' : 1,  # 119500\n",
    "        'BrkSide' : 1,  # 124300\n",
    "        'Sawyer' : 1,   # 135000\n",
    "        'Blueste' : 1,  # 137500\n",
    "        'SWISU' : 2,    # 139500\n",
    "        'NAmes' : 2,    # 140000\n",
    "        'NPkVill' : 2,  # 146000\n",
    "        'Mitchel' : 2,  # 153500\n",
    "        'SawyerW' : 2,  # 179900\n",
    "        'Gilbert' : 2,  # 181000\n",
    "        'NWAmes' : 2,   # 182900\n",
    "        'Blmngtn' : 2,  # 191000\n",
    "        'CollgCr' : 2,  # 197200\n",
    "        'ClearCr' : 3,  # 200250\n",
    "        'Crawfor' : 3,  # 200624\n",
    "        'Veenker' : 3,  # 218000\n",
    "        'Somerst' : 3,  # 225500\n",
    "        'Timber' : 3,   # 228475\n",
    "        'StoneBr' : 4,  # 278000\n",
    "        'NoRidge' : 4,  # 290000\n",
    "        'NridgHt' : 4,  # 315000\n",
    "    }\n",
    "\n",
    "    all_df['NeighborhoodBin'] = df['Neighborhood'].map(neighborhood_map)\n",
    "    return all_df\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# Convert categorical features using one-hot encoding.\n",
    "def onehot(onehot_df, df, column_name, fill_na, drop_name):\n",
    "    onehot_df[column_name] = df[column_name]\n",
    "    if fill_na is not None:\n",
    "        onehot_df[column_name].fillna(fill_na, inplace=True)\n",
    "\n",
    "    dummies = pd.get_dummies(onehot_df[column_name], prefix='_' + column_name)\n",
    "    \n",
    "    # Dropping one of the columns actually made the results slightly worse.\n",
    "    # if drop_name is not None:\n",
    "    #     dummies.drop(['_' + column_name + '_' + drop_name], axis=1, inplace=True)\n",
    "\n",
    "    onehot_df = onehot_df.join(dummies)\n",
    "    onehot_df = onehot_df.drop([column_name], axis=1)\n",
    "    return onehot_df\n",
    "\n",
    "def munge_onehot(df):\n",
    "    onehot_df = pd.DataFrame(index = df.index)\n",
    "\n",
    "    onehot_df = onehot(onehot_df, df, 'MSSubClass', None, '40')\n",
    "    onehot_df = onehot(onehot_df, df, 'MSZoning', 'RL', 'RH')\n",
    "    onehot_df = onehot(onehot_df, df, 'LotConfig', None, 'FR3')\n",
    "    onehot_df = onehot(onehot_df, df, 'Neighborhood', None, 'OldTown')\n",
    "    onehot_df = onehot(onehot_df, df, 'Condition1', None, 'RRNe')\n",
    "    onehot_df = onehot(onehot_df, df, 'BldgType', None, '2fmCon')\n",
    "    onehot_df = onehot(onehot_df, df, 'HouseStyle', None, '1.5Unf')\n",
    "    onehot_df = onehot(onehot_df, df, 'RoofStyle', None, 'Shed')\n",
    "    onehot_df = onehot(onehot_df, df, 'Exterior1st', 'VinylSd', 'CBlock')\n",
    "    onehot_df = onehot(onehot_df, df, 'Exterior2nd', 'VinylSd', 'CBlock')\n",
    "    onehot_df = onehot(onehot_df, df, 'Foundation', None, 'Wood')\n",
    "    onehot_df = onehot(onehot_df, df, 'SaleType', 'WD', 'Oth')\n",
    "    onehot_df = onehot(onehot_df, df, 'SaleCondition', 'Normal', 'AdjLand')\n",
    "\n",
    "    # Fill in missing MasVnrType for rows that do have a MasVnrArea.\n",
    "    temp_df = df[['MasVnrType', 'MasVnrArea']].copy()\n",
    "    idx = (df['MasVnrArea'] != 0) & ((df['MasVnrType'] == 'None') | (df['MasVnrType'].isnull()))\n",
    "    temp_df.loc[idx, 'MasVnrType'] = 'BrkFace'\n",
    "    onehot_df = onehot(onehot_df, temp_df, 'MasVnrType', 'None', 'BrkCmn')\n",
    "\n",
    "    # Also add the booleans from calc_df as dummy variables.\n",
    "    onehot_df = onehot(onehot_df, df, 'LotShape', None, 'IR3')\n",
    "    onehot_df = onehot(onehot_df, df, 'LandContour', None, 'Low')\n",
    "    onehot_df = onehot(onehot_df, df, 'LandSlope', None, 'Sev')\n",
    "    onehot_df = onehot(onehot_df, df, 'Electrical', 'SBrkr', 'FuseP')\n",
    "    onehot_df = onehot(onehot_df, df, 'GarageType', 'None', 'CarPort')\n",
    "    onehot_df = onehot(onehot_df, df, 'PavedDrive', None, 'P')\n",
    "    onehot_df = onehot(onehot_df, df, 'MiscFeature', 'None', 'Othr')\n",
    "\n",
    "    # Features we can probably ignore (but want to include anyway to see\n",
    "    # if they make any positive difference).\n",
    "    # Definitely ignoring Utilities: all records are 'AllPub', except for\n",
    "    # one 'NoSeWa' in the train set and 2 NA in the test set.\n",
    "    onehot_df = onehot(onehot_df, df, 'Street', None, 'Grvl')\n",
    "    onehot_df = onehot(onehot_df, df, 'Alley', 'None', 'Grvl')\n",
    "    onehot_df = onehot(onehot_df, df, 'Condition2', None, 'PosA')\n",
    "    onehot_df = onehot(onehot_df, df, 'RoofMatl', None, 'WdShake')\n",
    "    onehot_df = onehot(onehot_df, df, 'Heating', None, 'Wall')\n",
    "\n",
    "    # I have these as numerical variables too.\n",
    "    onehot_df = onehot(onehot_df, df, 'ExterQual', 'None', 'Ex')\n",
    "    onehot_df = onehot(onehot_df, df, 'ExterCond', 'None', 'Ex')\n",
    "    onehot_df = onehot(onehot_df, df, 'BsmtQual', 'None', 'Ex')\n",
    "    onehot_df = onehot(onehot_df, df, 'BsmtCond', 'None', 'Ex')\n",
    "    onehot_df = onehot(onehot_df, df, 'HeatingQC', 'None', 'Ex')\n",
    "    onehot_df = onehot(onehot_df, df, 'KitchenQual', 'TA', 'Ex')\n",
    "    onehot_df = onehot(onehot_df, df, 'FireplaceQu', 'None', 'Ex')\n",
    "    onehot_df = onehot(onehot_df, df, 'GarageQual', 'None', 'Ex')\n",
    "    onehot_df = onehot(onehot_df, df, 'GarageCond', 'None', 'Ex')\n",
    "    onehot_df = onehot(onehot_df, df, 'PoolQC', 'None', 'Ex')\n",
    "    onehot_df = onehot(onehot_df, df, 'BsmtExposure', 'None', 'Gd')\n",
    "    onehot_df = onehot(onehot_df, df, 'BsmtFinType1', 'None', 'GLQ')\n",
    "    onehot_df = onehot(onehot_df, df, 'BsmtFinType2', 'None', 'GLQ')\n",
    "    onehot_df = onehot(onehot_df, df, 'Functional', 'Typ', 'Typ')\n",
    "    onehot_df = onehot(onehot_df, df, 'GarageFinish', 'None', 'Fin')\n",
    "    onehot_df = onehot(onehot_df, df, 'Fence', 'None', 'MnPrv')\n",
    "    onehot_df = onehot(onehot_df, df, 'MoSold', None, None)\n",
    "    \n",
    "    # Divide up the years between 1871 and 2010 in slices of 20 years.\n",
    "    year_map = pd.concat(pd.Series('YearBin' + str(i+1), index=range(1871+i*20,1891+i*20)) for i in range(0, 7))\n",
    "\n",
    "    yearbin_df = pd.DataFrame(index = df.index)\n",
    "    yearbin_df['GarageYrBltBin'] = df.GarageYrBlt.map(year_map)\n",
    "    # yearbin_df['GarageYrBltBin'].fillna('NoGarage', inplace=True)\n",
    "    yearbin_df['GarageYrBltBin'].fillna('Unknown', inplace=True)\n",
    "\n",
    "    yearbin_df['YearBuiltBin'] = df.YearBuilt.map(year_map)\n",
    "    yearbin_df['YearRemodAddBin'] = df.YearRemodAdd.map(year_map)\n",
    "    \n",
    "    onehot_df = onehot(onehot_df, yearbin_df, 'GarageYrBltBin', None, None)\n",
    "    onehot_df = onehot(onehot_df, yearbin_df, 'YearBuiltBin', None, None)\n",
    "    onehot_df = onehot(onehot_df, yearbin_df, 'YearRemodAddBin', None, None)\n",
    "\n",
    "    return onehot_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (1456, 111)\n",
      "Test set size: (1459, 111)\n",
      "Features engineering..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\software\\anaconda\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:547: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "D:\\software\\anaconda\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:551: DataConversionWarning: Data with input dtype int32, int64, float64, object were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.979381\n",
      "Training set size: (1456, 403)\n",
      "Test set size: (1459, 403)\n",
      "Fitting ensemble and predicting..\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Cross-validation\n",
    "def evaludate_model(model, x, y):\n",
    "    # print('Cross_validation..')\n",
    "    n_splits_val = 3\n",
    "    kf = KFold(n_splits=n_splits_val, shuffle=False)\n",
    "    idx = 0\n",
    "    rmse_buf = np.empty(n_splits_val)\n",
    "    for train, test in kf.split(x):\n",
    "        model.fit(x.iloc[train], y.iloc[train])\n",
    "        y_cv = model.predict(x.iloc[test])\n",
    "        rmse_buf[idx] = rmse(y.iloc[test], y_cv)\n",
    "        # print('Interation #' + str(idx) + ': RMSE = %.5f' % rmse_buf[idx])\n",
    "        idx += 1\n",
    "\n",
    "    mean_rmse = np.mean(rmse_buf)\n",
    "    print('   Mean RMSE = %.5f' % mean_rmse + ' +/- %.5f' % np.std(rmse_buf))\n",
    "\n",
    "    return mean_rmse\n",
    "\n",
    "def evaludate_submodels(models, x, y):\n",
    "    # print('Cross_validation..')\n",
    "    n_splits_val = 10\n",
    "    kf = KFold(n_splits=n_splits_val, shuffle=False)\n",
    "    for m_i, model in enumerate(models.regressors): \n",
    "        rmse_buf = np.empty(n_splits_val)\n",
    "        idx = 0\n",
    "        for train, test in kf.split(x):\n",
    "            model.fit(x.iloc[train], y.iloc[train])\n",
    "            y_cv = model.predict(x.iloc[test])\n",
    "            rmse_buf[idx] = rmse(y.iloc[test], y_cv)\n",
    "            # print('Interation #' + str(idx) + ': RMSE = %.5f' % rmse_buf[idx])\n",
    "            idx += 1\n",
    "\n",
    "        mean_rmse = np.mean(rmse_buf)\n",
    "        print('Model #' + str(m_i) + ': mean RMSE = %.5f' % mean_rmse + \\\n",
    "            ' +/- %.5f' % np.std(rmse_buf))\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# Load the data.\n",
    "train_df = pd.read_csv(r'C:\\Users\\ZHOU-JC\\Desktop\\kaggle\\House Prices Advanced Regression Techniques/train.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\ZHOU-JC\\Desktop\\kaggle\\House Prices Advanced Regression Techniques/test.csv')\n",
    "\n",
    "# There are a few houses with more than 4000 sq ft living area that are\n",
    "# outliers, so we drop them from the training data. (There is also one in\n",
    "# the test set but we obviously can't drop that one.)\n",
    "train_df.drop(train_df[train_df['GrLivArea'] > 4000].index, inplace=True)\n",
    "\n",
    "# The test example with ID 666 has GarageArea, GarageCars, and GarageType \n",
    "# but none of the other fields, so use the mode and median to fill them in.\n",
    "test_df.loc[666, 'GarageQual'] = 'TA'\n",
    "test_df.loc[666, 'GarageCond'] = 'TA'\n",
    "test_df.loc[666, 'GarageFinish'] = 'Unf'\n",
    "test_df.loc[666, 'GarageYrBlt'] = '1980'\n",
    "\n",
    "# The test example 1116 only has GarageType but no other information. We'll \n",
    "# assume it does not have a garage.\n",
    "test_df.loc[1116, 'GarageType'] = np.nan\n",
    "\n",
    "# For imputing missing values: fill in missing LotFrontage values by the median\n",
    "# LotFrontage of the neighborhood.\n",
    "lot_frontage_by_neighborhood = train_df['LotFrontage'].groupby(train_df['Neighborhood'])\n",
    "\n",
    "# Used to convert categorical features into ordinal numbers.\n",
    "# (There's probably an easier way to do this, but it works.)\n",
    "le = LabelEncoder()\n",
    "\n",
    "train_df_munged = munge(train_df)\n",
    "test_df_munged = munge(test_df)\n",
    "\n",
    "print('Training set size:', train_df_munged.shape)\n",
    "print('Test set size:', test_df_munged.shape)\n",
    "\n",
    "print('Features engineering..')\n",
    "\n",
    "# Copy NeighborhoodBin into a temporary DataFrame because we want to use the\n",
    "# unscaled version later on (to one-hot encode it). \n",
    "neighborhood_bin_train = pd.DataFrame(index = train_df.index)\n",
    "neighborhood_bin_train['NeighborhoodBin'] = train_df_munged['NeighborhoodBin']\n",
    "neighborhood_bin_test = pd.DataFrame(index = test_df.index)\n",
    "neighborhood_bin_test['NeighborhoodBin'] = test_df_munged['NeighborhoodBin']\n",
    "\n",
    "################################################################################\n",
    "\n",
    "numeric_features = train_df_munged.dtypes[train_df_munged.dtypes != 'object'].index\n",
    "\n",
    "# Transform the skewed numeric features by taking log(feature + 1).\n",
    "# This will make the features more normal.\n",
    "skewed = train_df_munged[numeric_features].apply(lambda x: skew(x.dropna().astype(float)))\n",
    "skewed = skewed[skewed > 0.8]\n",
    "skewed = skewed.index\n",
    "\n",
    "train_df_munged[skewed] = np.log1p(train_df_munged[skewed])\n",
    "test_df_munged[skewed] = np.log1p(test_df_munged[skewed])\n",
    "\n",
    "# Additional processing: scale the data.   \n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df_munged[numeric_features])\n",
    "\n",
    "scaled = scaler.transform(train_df_munged[numeric_features])\n",
    "for i, col in enumerate(numeric_features):\n",
    "    train_df_munged[col] = scaled[:, i]\n",
    "\n",
    "scaled = scaler.transform(test_df_munged[numeric_features])\n",
    "for i, col in enumerate(numeric_features):\n",
    "    test_df_munged[col] = scaled[:, i]\n",
    "\n",
    "\n",
    "# Add the one-hot encoded categorical features.\n",
    "onehot_df = munge_onehot(train_df)\n",
    "onehot_df = onehot(onehot_df, neighborhood_bin_train, 'NeighborhoodBin', None, None)\n",
    "train_df_munged = train_df_munged.join(onehot_df)\n",
    "\n",
    "# These onehot columns are missing in the test data, so drop them from the\n",
    "# training data or we might overfit on them.\n",
    "drop_cols = [\n",
    "                '_Exterior1st_ImStucc', '_Exterior1st_Stone',\n",
    "                '_Exterior2nd_Other','_HouseStyle_2.5Fin', \n",
    "            \n",
    "                '_RoofMatl_Membran', '_RoofMatl_Metal', '_RoofMatl_Roll',\n",
    "                '_Condition2_RRAe', '_Condition2_RRAn', '_Condition2_RRNn',\n",
    "                '_Heating_Floor', '_Heating_OthW',\n",
    "\n",
    "                '_Electrical_Mix', \n",
    "                '_MiscFeature_TenC',\n",
    "                '_GarageQual_Ex', '_PoolQC_Fa'\n",
    "            ]\n",
    "train_df_munged.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "onehot_df = munge_onehot(test_df)\n",
    "onehot_df = onehot(onehot_df, neighborhood_bin_test, 'NeighborhoodBin', None, None)\n",
    "test_df_munged = test_df_munged.join(onehot_df)\n",
    "\n",
    "# This column is missing in the training data. There is only one example with\n",
    "# this value in the test set. So just drop it.\n",
    "test_df_munged.drop(['_MSSubClass_150'], axis=1, inplace=True)\n",
    "\n",
    "# Drop these columns. They are either not very helpful or they cause overfitting.\n",
    "drop_cols = [\n",
    "    '_Condition2_PosN',    # only two are not zero\n",
    "    '_MSZoning_C (all)',\n",
    "    '_MSSubClass_160',\n",
    "]\n",
    "# Realy overfit!\n",
    "train_df_munged.drop(drop_cols, axis=1, inplace=True)\n",
    "test_df_munged.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# We take the log here because the error metric is between the log of the\n",
    "# SalePrice and the log of the predicted price. That does mean we need to \n",
    "# exp() the prediction to get an actual sale price.\n",
    "label_df = pd.DataFrame(index = train_df_munged.index, columns=['SalePrice'])\n",
    "label_df['SalePrice'] = np.log(train_df['SalePrice'])\n",
    "print(datetime.datetime.now()-start_time)   \n",
    "\n",
    "print('Training set size:', train_df_munged.shape)\n",
    "print('Test set size:', test_df_munged.shape)\n",
    "\n",
    "################################################################################\n",
    "regr1 = xgb.XGBRegressor(\n",
    "                 colsample_bytree=0.2,\n",
    "                 gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=4,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=30000,                                                                  \n",
    "                 reg_alpha=0.9,\n",
    "                 reg_lambda=0.6,\n",
    "                 subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "\n",
    "best_alpha = 0.00098\n",
    "regr2 = Lasso(alpha=best_alpha, max_iter=50000)\n",
    "\n",
    "regr3 = ElasticNet(alpha=0.001)\n",
    "\n",
    "regr4 = KernelRidge(alpha=0.3, kernel='polynomial', degree=2, coef0=1.85\n",
    "\n",
    "regr = CustomEnsembleRegressor([regr1, regr2, regr3, regr4])\n",
    "\n",
    "# Evaluation was commented to make it run as  kernel\n",
    "# print('Evaluating each model separately..')\n",
    "# evaludate_submodels(regr, train_df_munged, label_df)\n",
    "\n",
    "# print('Evaluating ensemble..')\n",
    "# evaludate_model(regr, train_df_munged, label_df)\n",
    "\n",
    "print('Fitting ensemble and predicting..')\n",
    "# Fit the ensemble\n",
    "regr.fit(train_df_munged, label_df)\n",
    "\n",
    "# Run prediction on the Kaggle test set.\n",
    "y_pred = regr.predict(test_df_munged)\n",
    "print(datetime.datetime.now()-start_time)   \n",
    "\n",
    "################################################################################\n",
    "\n",
    "print('Saving results..')\n",
    "# Blend the results of the two regressors and save the prediction to a CSV file.  \n",
    "y_pred = np.exp(y_pred)\n",
    "\n",
    "pred_df = pd.DataFrame(y_pred, index=test_df['Id'], columns=['SalePrice'])\n",
    "pred_df.to_csv('ensemble_output.csv', header=True, index_label='Id')\n",
    "print(datetime.datetime.now()-start_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1456, 403)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_munged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
