{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T05:14:11.462680Z",
     "start_time": "2020-04-17T05:14:07.669572Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 05:14:09.089147 140285051234048 file_utils.py:41] PyTorch version 1.2.0 available.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, AdamW, BertModel, BertPreTrainedModel, BertConfig, SquadExample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T05:14:11.526669Z",
     "start_time": "2020-04-17T05:14:11.466620Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 05:14:11.471177 140285051234048 configuration_utils.py:281] loading configuration file /home/zhoujx/Pretrained_models/chinese_roberta_wwm_large_ext_pytorch/bert_config.json\n",
      "I0417 05:14:11.473556 140285051234048 configuration_utils.py:319] Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0417 05:14:11.477057 140285051234048 tokenization_utils.py:420] Model name '/home/zhoujx/Pretrained_models/chinese_roberta_wwm_large_ext_pytorch/vocab.txt' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '/home/zhoujx/Pretrained_models/chinese_roberta_wwm_large_ext_pytorch/vocab.txt' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "W0417 05:14:11.477973 140285051234048 tokenization_utils.py:432] Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n",
      "I0417 05:14:11.478952 140285051234048 tokenization_utils.py:502] loading file /home/zhoujx/Pretrained_models/chinese_roberta_wwm_large_ext_pytorch/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "bert_config = BertConfig.from_pretrained(r'/home/zhoujx/Pretrained_models/chinese_roberta_wwm_large_ext_pytorch/bert_config.json', output_hidden_states=True)\n",
    "tokenizer  = BertTokenizer.from_pretrained(r'/home/zhoujx/Pretrained_models/chinese_roberta_wwm_large_ext_pytorch/vocab.txt', config=bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T05:30:07.151098Z",
     "start_time": "2020-04-17T05:30:07.131543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[unused23]']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辅助函数\n",
    ">重新寻找start_position和end_position，避免分词后位置对不上\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T12:53:27.352126Z",
     "start_time": "2020-04-13T12:53:27.342805Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 重新寻找start_position和end_position\n",
    "def contains(small, big):\n",
    "    for i in range(len(big)-len(small)+1):\n",
    "        for j in range(len(small)):\n",
    "            if big[i+j] != small[j]:\n",
    "                break\n",
    "        else:\n",
    "            return i, i+len(small)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_data & dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T12:53:28.875852Z",
     "start_time": "2020-04-13T12:53:28.847683Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(data_path):\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        load_dict = json.load(f)\n",
    "    datas = load_dict['data'][0]['paragraphs']\n",
    "    \n",
    "    query_id_list = []\n",
    "    context_list = []\n",
    "    query_text_list = []\n",
    "    answer_list = []\n",
    "    input_ids_list = []\n",
    "    token_type_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    for document in tqdm(datas):\n",
    "        context = document['context'].strip()\n",
    "        for qa in (document['qas']):\n",
    "            query_id = qa['id']\n",
    "            query_text = qa['question'].strip()\n",
    "            answer = qa['answers'][0]['text']\n",
    "            tokenize_out = tokenizer.encode_plus(query_text, \n",
    "                                                                         context, max_length=512, \n",
    "                                                                         pad_to_max_length=True)\n",
    "            input_ids = tokenize_out['input_ids']\n",
    "            token_type_ids = tokenize_out['token_type_ids']\n",
    "            attention_mask = tokenize_out['attention_mask']\n",
    "            # \n",
    "            query_id_list.append(query_id)\n",
    "            context_list.append(context)\n",
    "            query_text_list.append(query_text)\n",
    "            answer_list.append(answer)\n",
    "            input_ids_list.append(input_ids)\n",
    "            token_type_ids_list.append(token_type_ids)\n",
    "            attention_mask_list.append(attention_mask)            \n",
    "            \n",
    "    df_data = pd.DataFrame({'query_id' : query_id_list,\n",
    "                                              'context' : context_list,\n",
    "                                              'question' : query_text_list,\n",
    "                                             'answer' : answer_list,\n",
    "                                             'input_ids' : input_ids_list,\n",
    "                                             'token_type_ids' : token_type_ids_list,\n",
    "                                             'attention_mask' : attention_mask_list})\n",
    "    \n",
    "    # 分词\n",
    "    for col in ['context', 'question', 'answer']:\n",
    "        df_data[col + '_token'] = df_data.apply(lambda x: tokenizer.tokenize(x[col]), axis=1)\n",
    "        print(col + '：finished!!!!')\n",
    "\n",
    "    # 重新确定start_end\n",
    "    df_data['start_end_span'] = df_data.apply(lambda x: contains(x['answer_token'], x['context_token']), axis=1)\n",
    "    df_data['start_position'] = df_data.apply(lambda x: x['start_end_span'][0] if x['start_end_span'] != False else np.nan, axis=1)\n",
    "    df_data['end_position'] = df_data.apply(lambda x: x['start_end_span'][1] if x['start_end_span'] != False else np.nan, axis=1)\n",
    "    # 去除np.nan值\n",
    "    df_data.dropna(subset=['start_position', 'end_position'], inplace=True)\n",
    "    # 修正\n",
    "    df_data['start_position'] = df_data['start_position'].astype(int)\n",
    "    df_data['start_position'] = df_data.apply(lambda x:x['start_position'] + len(x['question_token']) +2, axis=1)\n",
    "    df_data['end_position']   = df_data['end_position'].astype(int)\n",
    "    df_data['end_position']   = df_data.apply(lambda x:x['end_position'] + len(x['question_token']) +2, axis=1)\n",
    "    # \n",
    "    df_data.drop(['context_token', 'question_token', 'answer_token', 'start_end_span'], inplace=True, axis=1)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T12:55:41.609910Z",
     "start_time": "2020-04-13T12:53:30.801237Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14520/14520 [01:05<00:00, 222.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context：finished!!!!\n",
      "question：finished!!!!\n",
      "answer：finished!!!!\n"
     ]
    }
   ],
   "source": [
    "df_train = get_data('./train.json')\n",
    "# df_dev   = get_data('./dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T12:55:46.280192Z",
     "start_time": "2020-04-13T12:55:41.613703Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('./df_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T22:58:38.186415Z",
     "start_time": "2020-04-09T22:58:37.943964Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dev.to_csv('./df_dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T12:55:53.747554Z",
     "start_time": "2020-04-13T12:55:53.735862Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_data(data_path):\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        load_dict = json.load(f)\n",
    "    datas = load_dict['data'][0]['paragraphs']\n",
    "       \n",
    "    query_id_list = []\n",
    "    context_list = []\n",
    "    query_text_list = []\n",
    "    input_ids_list = []\n",
    "    token_type_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    \n",
    "    for document in tqdm(datas):\n",
    "        context = document['context'].strip()\n",
    "        for qa in (document['qas']):\n",
    "            query_id = qa['id']\n",
    "            query_text = qa['question'].strip()\n",
    "            tokenize_out = tokenizer.encode_plus(query_text, \n",
    "                                                                         context, max_length=512, \n",
    "                                                                         pad_to_max_length=True)\n",
    "            input_ids = tokenize_out['input_ids']\n",
    "            token_type_ids = tokenize_out['token_type_ids']\n",
    "            attention_mask = tokenize_out['attention_mask']\n",
    "            # \n",
    "            query_id_list.append(query_id)\n",
    "            context_list.append(context)\n",
    "            query_text_list.append(query_text)\n",
    "            input_ids_list.append(input_ids)\n",
    "            token_type_ids_list.append(token_type_ids)\n",
    "            attention_mask_list.append(attention_mask)\n",
    "            \n",
    "    df_data = pd.DataFrame({'query_id' : query_id_list,\n",
    "                                              'context' : context_list,\n",
    "                                              'question' : query_text_list,\n",
    "                                              'input_ids' : input_ids_list,\n",
    "                                              'token_type_ids' : token_type_ids_list,\n",
    "                                              'attention_mask' : attention_mask_list})\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('./df_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T23:52:27.646077Z",
     "start_time": "2020-04-13T23:47:29.328453Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30703/30703 [04:36<00:00, 110.95it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test = get_test_data('./test1.json')\n",
    "df_test.to_csv('./df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T12:55:53.733144Z",
     "start_time": "2020-04-13T12:55:46.304296Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1417/1417 [00:06<00:00, 221.22it/s]\n"
     ]
    }
   ],
   "source": [
    "df_dev = get_test_data('./dev.json')\n",
    "df_dev.to_csv('./df_dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T03:01:00.078021Z",
     "start_time": "2020-04-14T03:00:59.490575Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./test1.json', 'r', encoding='utf-8') as f:\n",
    "    load_dict = json.load(f)\n",
    "datas = load_dict['data'][0]['paragraphs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T03:01:50.968445Z",
     "start_time": "2020-04-14T03:01:48.714318Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./df_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T09:19:45.176824Z",
     "start_time": "2020-04-14T09:19:45.157109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3c41636fb3f3a1bca8dbf60e1d9a8d18</td>\n",
       "      <td>藏蓝色，兼于蓝色和黑色之间，既有蓝色的沉静安宁，也有黑色的神秘成熟，既有黑色的收敛效果，又不乏蓝色的洁净长久，虽然不会大热流行，却是可以长久的信任，当藏蓝色与其他颜色相遇，你便会懂得它内在的涵养。藏蓝色+橙色单纯的藏蓝色会给人很严肃的气氛，橙色的点缀让藏蓝色也充满时尚活力。藏蓝色+白色白色是藏蓝色的最佳搭档，两者搭档最容易显得很干净，藏蓝色和白色营造的洗练感，让通勤装永远都不会过时，展现出都市女性的利落感。藏蓝色+粉色藏蓝色和粉色组合散发出成熟优雅的女人味，让粉色显出别样娇嫩。藏蓝色+米色藏蓝色和米色的搭配散发出浓郁的知性气质，稚气的设计细节更显年轻。藏蓝色+红色藏蓝色和红色的搭配更加的沉稳，也更具存在感，如果是面积差不多的服装来搭配，可以用红色的小物点缀来巧妙的平衡。藏蓝色+松石绿藏蓝色搭配柔和的松石绿色给人上品好品质的感觉，用凉鞋和项链来点缀更加具有层次感。藏蓝色+黄色明亮的黄...</td>\n",
       "      <td>藏蓝色配什么颜色好看</td>\n",
       "      <td>[101, 5966, 5905, 5682, 6981, 784, 720, 7582, 5682, 1962, 4692, 102, 5966, 5905, 5682, 8024, 1076, 754, 5905, 5682, 1469, 7946, 5682, 722, 7313, 8024, 3188, 3300, 5905, 5682, 4638, 3756, 7474, 2128, 2123, 8024, 738, 3300, 7946, 5682, 4638, 4868, 4908, 2768, 4225, 8024, 3188, 3300, 7946, 5682, 4638, 3119, 3137, 3126, 3362, 8024, 1348, 679, 726, 5905, 5682, 4638, 3815, 1112, 7270, 719, 8024, 600...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8edd3333dcff47508ebba5a6249fa8e9</td>\n",
       "      <td>阳光板大部分使用的是聚碳酸酯（PC）原料生产，利用空挤压工艺在耐候性脆弱的PC板材上空挤压UV树脂，质量好一点的板面均匀分布有高浓度的UV层，阻挡紫外线的穿过，防止板材黄变，延长板材寿命使产品使用寿命达到10年以上。并且产品具有长期持续透明性的特点。（有单面和双面UV防护）。用途：住宅/商厦采光天幕，工厂厂房 仓库采光顶，体育场馆采光顶，广告牌，通道/停车棚，游泳池/温室覆盖，室内隔断。另本司有隔热保温的PC板材做温棚 遮阳棚 都不错2832217048@qq.com</td>\n",
       "      <td>阳光板雨棚能用几年</td>\n",
       "      <td>[101, 7345, 1045, 3352, 7433, 3476, 5543, 4500, 1126, 2399, 102, 7345, 1045, 3352, 1920, 6956, 1146, 886, 4500, 4638, 3221, 5471, 4823, 7000, 6994, 8020, 8295, 8021, 1333, 3160, 4495, 772, 8024, 1164, 4500, 4958, 2915, 1327, 2339, 5686, 1762, 5447, 952, 2595, 5546, 2483, 4638, 8295, 3352, 3332, 677, 4958, 2915, 1327, 9473, 3409, 5544, 8024, 6574, 7030, 1962, 671, 4157, 4638, 3352, 7481, 1772, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>386169bb13528eb53a923e3f068cf0db</td>\n",
       "      <td>手术方式的话用微创的更好,微创手术术野清晰,手术时间更少,伤口小术后患者恢复好。但如果是低位直肠癌的话建议用冷冻治疗,冷冻治疗与微创手术相比几乎没有创口,术后生存率一样,大部分低位超低位直肠癌患者需要做人工肛门,冷冻治疗可以保留肛门和肛门功能。手术费用各地公立医院的定价都是由物价局定价的,等级和区域的不同会有影响,在我们医院(公立三甲)直肠癌微创手术大概5万元。冷冻治疗大概2万元。</td>\n",
       "      <td>肠癌手术费大概多少钱</td>\n",
       "      <td>[101, 5499, 4617, 2797, 3318, 6589, 1920, 3519, 1914, 2208, 7178, 102, 2797, 3318, 3175, 2466, 4638, 6413, 4500, 2544, 1158, 4638, 3291, 1962, 117, 2544, 1158, 2797, 3318, 3318, 7029, 3926, 3251, 117, 2797, 3318, 3198, 7313, 3291, 2208, 117, 839, 1366, 2207, 3318, 1400, 2642, 5442, 2612, 1908, 1962, 511, 852, 1963, 3362, 3221, 856, 855, 4684, 5499, 4617, 4638, 6413, 2456, 6379, 4500, 1107, 110...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>362d218b681886d4644b6c9ca991675a</td>\n",
       "      <td>现在橱柜的箱体板材主要有实木颗粒板 和实木多层 ,大的品牌主要是实木颗粒板因为它的防水防潮性能和握钉力好,但是因为它们的环保级别不一样,价格也是不一样的.最好的可以达到欧标EO级它的甲醛释放量&lt;0.05mg/l 橱柜门板的主要种类及特点 门板作为表现橱柜外观和总体质量的主要部分,通常是订购橱柜时首先要考虑的。消费者选择橱柜门板时,应考虑款式造型、颜色搭配、易于清理、抗变形性、防潮、防水性、表面耐磨性及是否环保等决定橱柜质量和使用寿命的几个关键性能指标。随着新材料、新工艺的不断出现,门板种类也越来越丰富。目前市场上常见的橱柜门板主要有以下几种: (1)防火板门板:这种门板通常选用环保E1级大芯板作基材,外贴优质、环保防火板。具有耐磨、耐高温、耐划、易清洁以及不易变形、色泽靓丽等特性,成为门板的常用材料。现在橱柜的箱体板材主要有实木颗粒板和实木多层,大的品牌主要是实木颗粒板因为它的防水...</td>\n",
       "      <td>橱柜用什么板材好</td>\n",
       "      <td>[101, 3586, 3385, 4500, 784, 720, 3352, 3332, 1962, 102, 4385, 1762, 3586, 3385, 4638, 5056, 860, 3352, 3332, 712, 6206, 3300, 2141, 3312, 7578, 5108, 3352, 1469, 2141, 3312, 1914, 2231, 117, 1920, 4638, 1501, 4277, 712, 6206, 3221, 2141, 3312, 7578, 5108, 3352, 1728, 711, 2124, 4638, 7344, 3717, 7344, 4060, 2595, 5543, 1469, 2995, 7152, 1213, 1962, 117, 852, 3221, 1728, 711, 2124, 812, 4638, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9754ed445e8745360b75665c315804f9</td>\n",
       "      <td>一般来说实木的胡桃木较橡木好。黄金胡桃木又称为：金丝胡桃木；胡桃木易于用手工和机械工具加工。适于敲钉、螺钻和胶合。可以持久保留油漆和染色，可打磨成特殊的最终效果。干燥得很慢，需要小心避免窑中烘干后的降等损失。胡桃木有良好的尺寸稳定性。且花纹特殊，木质名贵，少有家具制造商能够将其特性完美的体现出来。如果有更多问题，可以点击ID咨询。</td>\n",
       "      <td>橡木胡桃木哪个好</td>\n",
       "      <td>[101, 3583, 3312, 5529, 3425, 3312, 1525, 702, 1962, 102, 671, 5663, 3341, 6432, 2141, 3312, 4638, 5529, 3425, 3312, 6772, 3583, 3312, 1962, 511, 7942, 7032, 5529, 3425, 3312, 1348, 4917, 711, 8038, 7032, 692, 5529, 3425, 3312, 8039, 5529, 3425, 3312, 3211, 754, 4500, 2797, 2339, 1469, 3322, 3462, 2339, 1072, 1217, 2339, 511, 6844, 754, 3145, 7152, 510, 6090, 7183, 1469, 5540, 1394, 511, 1377,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           query_id  \\\n",
       "0  3c41636fb3f3a1bca8dbf60e1d9a8d18   \n",
       "1  8edd3333dcff47508ebba5a6249fa8e9   \n",
       "2  386169bb13528eb53a923e3f068cf0db   \n",
       "3  362d218b681886d4644b6c9ca991675a   \n",
       "4  9754ed445e8745360b75665c315804f9   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                           context  \\\n",
       "0  藏蓝色，兼于蓝色和黑色之间，既有蓝色的沉静安宁，也有黑色的神秘成熟，既有黑色的收敛效果，又不乏蓝色的洁净长久，虽然不会大热流行，却是可以长久的信任，当藏蓝色与其他颜色相遇，你便会懂得它内在的涵养。藏蓝色+橙色单纯的藏蓝色会给人很严肃的气氛，橙色的点缀让藏蓝色也充满时尚活力。藏蓝色+白色白色是藏蓝色的最佳搭档，两者搭档最容易显得很干净，藏蓝色和白色营造的洗练感，让通勤装永远都不会过时，展现出都市女性的利落感。藏蓝色+粉色藏蓝色和粉色组合散发出成熟优雅的女人味，让粉色显出别样娇嫩。藏蓝色+米色藏蓝色和米色的搭配散发出浓郁的知性气质，稚气的设计细节更显年轻。藏蓝色+红色藏蓝色和红色的搭配更加的沉稳，也更具存在感，如果是面积差不多的服装来搭配，可以用红色的小物点缀来巧妙的平衡。藏蓝色+松石绿藏蓝色搭配柔和的松石绿色给人上品好品质的感觉，用凉鞋和项链来点缀更加具有层次感。藏蓝色+黄色明亮的黄...   \n",
       "1                                                                                                                                                                     阳光板大部分使用的是聚碳酸酯（PC）原料生产，利用空挤压工艺在耐候性脆弱的PC板材上空挤压UV树脂，质量好一点的板面均匀分布有高浓度的UV层，阻挡紫外线的穿过，防止板材黄变，延长板材寿命使产品使用寿命达到10年以上。并且产品具有长期持续透明性的特点。（有单面和双面UV防护）。用途：住宅/商厦采光天幕，工厂厂房 仓库采光顶，体育场馆采光顶，广告牌，通道/停车棚，游泳池/温室覆盖，室内隔断。另本司有隔热保温的PC板材做温棚 遮阳棚 都不错2832217048@qq.com   \n",
       "2                                                                                                                                                                                                                 手术方式的话用微创的更好,微创手术术野清晰,手术时间更少,伤口小术后患者恢复好。但如果是低位直肠癌的话建议用冷冻治疗,冷冻治疗与微创手术相比几乎没有创口,术后生存率一样,大部分低位超低位直肠癌患者需要做人工肛门,冷冻治疗可以保留肛门和肛门功能。手术费用各地公立医院的定价都是由物价局定价的,等级和区域的不同会有影响,在我们医院(公立三甲)直肠癌微创手术大概5万元。冷冻治疗大概2万元。   \n",
       "3  现在橱柜的箱体板材主要有实木颗粒板 和实木多层 ,大的品牌主要是实木颗粒板因为它的防水防潮性能和握钉力好,但是因为它们的环保级别不一样,价格也是不一样的.最好的可以达到欧标EO级它的甲醛释放量<0.05mg/l 橱柜门板的主要种类及特点 门板作为表现橱柜外观和总体质量的主要部分,通常是订购橱柜时首先要考虑的。消费者选择橱柜门板时,应考虑款式造型、颜色搭配、易于清理、抗变形性、防潮、防水性、表面耐磨性及是否环保等决定橱柜质量和使用寿命的几个关键性能指标。随着新材料、新工艺的不断出现,门板种类也越来越丰富。目前市场上常见的橱柜门板主要有以下几种: (1)防火板门板:这种门板通常选用环保E1级大芯板作基材,外贴优质、环保防火板。具有耐磨、耐高温、耐划、易清洁以及不易变形、色泽靓丽等特性,成为门板的常用材料。现在橱柜的箱体板材主要有实木颗粒板和实木多层,大的品牌主要是实木颗粒板因为它的防水...   \n",
       "4                                                                                                                                                                                                                                           一般来说实木的胡桃木较橡木好。黄金胡桃木又称为：金丝胡桃木；胡桃木易于用手工和机械工具加工。适于敲钉、螺钻和胶合。可以持久保留油漆和染色，可打磨成特殊的最终效果。干燥得很慢，需要小心避免窑中烘干后的降等损失。胡桃木有良好的尺寸稳定性。且花纹特殊，木质名贵，少有家具制造商能够将其特性完美的体现出来。如果有更多问题，可以点击ID咨询。   \n",
       "\n",
       "     question  \\\n",
       "0  藏蓝色配什么颜色好看   \n",
       "1   阳光板雨棚能用几年   \n",
       "2  肠癌手术费大概多少钱   \n",
       "3    橱柜用什么板材好   \n",
       "4    橡木胡桃木哪个好   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                         input_ids  \\\n",
       "0  [101, 5966, 5905, 5682, 6981, 784, 720, 7582, 5682, 1962, 4692, 102, 5966, 5905, 5682, 8024, 1076, 754, 5905, 5682, 1469, 7946, 5682, 722, 7313, 8024, 3188, 3300, 5905, 5682, 4638, 3756, 7474, 2128, 2123, 8024, 738, 3300, 7946, 5682, 4638, 4868, 4908, 2768, 4225, 8024, 3188, 3300, 7946, 5682, 4638, 3119, 3137, 3126, 3362, 8024, 1348, 679, 726, 5905, 5682, 4638, 3815, 1112, 7270, 719, 8024, 600...   \n",
       "1  [101, 7345, 1045, 3352, 7433, 3476, 5543, 4500, 1126, 2399, 102, 7345, 1045, 3352, 1920, 6956, 1146, 886, 4500, 4638, 3221, 5471, 4823, 7000, 6994, 8020, 8295, 8021, 1333, 3160, 4495, 772, 8024, 1164, 4500, 4958, 2915, 1327, 2339, 5686, 1762, 5447, 952, 2595, 5546, 2483, 4638, 8295, 3352, 3332, 677, 4958, 2915, 1327, 9473, 3409, 5544, 8024, 6574, 7030, 1962, 671, 4157, 4638, 3352, 7481, 1772, ...   \n",
       "2  [101, 5499, 4617, 2797, 3318, 6589, 1920, 3519, 1914, 2208, 7178, 102, 2797, 3318, 3175, 2466, 4638, 6413, 4500, 2544, 1158, 4638, 3291, 1962, 117, 2544, 1158, 2797, 3318, 3318, 7029, 3926, 3251, 117, 2797, 3318, 3198, 7313, 3291, 2208, 117, 839, 1366, 2207, 3318, 1400, 2642, 5442, 2612, 1908, 1962, 511, 852, 1963, 3362, 3221, 856, 855, 4684, 5499, 4617, 4638, 6413, 2456, 6379, 4500, 1107, 110...   \n",
       "3  [101, 3586, 3385, 4500, 784, 720, 3352, 3332, 1962, 102, 4385, 1762, 3586, 3385, 4638, 5056, 860, 3352, 3332, 712, 6206, 3300, 2141, 3312, 7578, 5108, 3352, 1469, 2141, 3312, 1914, 2231, 117, 1920, 4638, 1501, 4277, 712, 6206, 3221, 2141, 3312, 7578, 5108, 3352, 1728, 711, 2124, 4638, 7344, 3717, 7344, 4060, 2595, 5543, 1469, 2995, 7152, 1213, 1962, 117, 852, 3221, 1728, 711, 2124, 812, 4638, ...   \n",
       "4  [101, 3583, 3312, 5529, 3425, 3312, 1525, 702, 1962, 102, 671, 5663, 3341, 6432, 2141, 3312, 4638, 5529, 3425, 3312, 6772, 3583, 3312, 1962, 511, 7942, 7032, 5529, 3425, 3312, 1348, 4917, 711, 8038, 7032, 692, 5529, 3425, 3312, 8039, 5529, 3425, 3312, 3211, 754, 4500, 2797, 2339, 1469, 3322, 3462, 2339, 1072, 1217, 2339, 511, 6844, 754, 3145, 7152, 510, 6090, 7183, 1469, 5540, 1394, 511, 1377,...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                    token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                    attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T03:08:48.868612Z",
     "start_time": "2020-04-14T03:08:48.864073Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T03:08:05.175321Z",
     "start_time": "2020-04-14T03:08:05.169958Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
